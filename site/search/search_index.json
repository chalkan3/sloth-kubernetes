{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Production Kubernetes Cluster - Complete Documentation","text":""},{"location":"#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ol> <li>Overview</li> <li>Architecture</li> <li>Infrastructure</li> <li>Networking &amp; VPN</li> <li>Node Configuration</li> <li>Deployed Services</li> <li>Access &amp; Authentication</li> <li>Deployment Guide</li> <li>Maintenance &amp; Operations</li> <li>Troubleshooting</li> </ol>"},{"location":"#overview","title":"Overview","text":"<p>Cluster Name: <code>production</code> Kubernetes Distribution: RKE2 v1.33.5 Container Runtime: containerd 2.1.4-k3s2 Infrastructure as Code: Pulumi (Go) Cloud Providers: DigitalOcean + Linode (Multi-cloud) Network: WireGuard VPN Mesh API Endpoint: https://api.chalkan3.com.br:6443</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u2705 High Availability: 3 master nodes with etcd cluster</li> <li>\u2705 Multi-cloud: Nodes distributed across DigitalOcean and Linode</li> <li>\u2705 Private Network: Full WireGuard VPN mesh between all nodes</li> <li>\u2705 Secure: No public exposure, VPN-only access</li> <li>\u2705 Automated: Provisioned via Pulumi with automatic dependency installation</li> <li>\u2705 Production Ready: ArgoCD for GitOps, Nginx Ingress, SSL/TLS</li> </ul>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#cluster-topology","title":"Cluster Topology","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Control Plane (HA)                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502  master-1   \u2502  \u2502  master-2   \u2502  \u2502  master-3   \u2502            \u2502\n\u2502  \u2502 10.8.0.10   \u2502  \u2502 10.8.0.11   \u2502  \u2502 10.8.0.12   \u2502            \u2502\n\u2502  \u2502 DigitalOcean\u2502  \u2502   Linode    \u2502  \u2502   Linode    \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u2502 WireGuard VPN Mesh\n                              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Worker Nodes                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502  worker-1   \u2502  \u2502  worker-2   \u2502  \u2502  worker-3   \u2502            \u2502\n\u2502  \u2502 10.8.0.13   \u2502  \u2502 10.8.0.14   \u2502  \u2502 10.8.0.15   \u2502            \u2502\n\u2502  \u2502 (tools)     \u2502  \u2502 (tools)     \u2502  \u2502  (misc)     \u2502            \u2502\n\u2502  \u2502DigitalOcean \u2502  \u2502DigitalOcean \u2502  \u2502   Linode    \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#network-architecture","title":"Network Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    VPN Server (AWS)                              \u2502\n\u2502                     10.8.0.1                                     \u2502\n\u2502                   3.93.242.31:51820                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u2502 WireGuard VPN\n                           \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                  \u2502                  \u2502\n   Your Client      K8s Master Nodes    K8s Worker Nodes\n   10.8.0.2         10.8.0.10-12        10.8.0.13-15\n</code></pre>"},{"location":"#infrastructure","title":"Infrastructure","text":""},{"location":"#node-specifications","title":"Node Specifications","text":""},{"location":"#master-nodes-3x","title":"Master Nodes (3x)","text":"Node Provider VPN IP Public IP Size/Type OS Location master-1 DigitalOcean 10.8.0.10 159.203.130.45 s-2vcpu-4gb Ubuntu 22.04 NYC3 master-2 Linode 10.8.0.11 96.126.106.67 g6-standard-2 Ubuntu 22.04 US-East master-3 Linode 10.8.0.12 96.126.106.52 g6-standard-2 Ubuntu 22.04 US-East <p>Resources per Master: - 2 vCPUs - 4 GB RAM - 80 GB SSD - Roles: <code>control-plane</code>, <code>etcd</code>, <code>master</code></p>"},{"location":"#worker-nodes-3x","title":"Worker Nodes (3x)","text":"Node Provider VPN IP Public IP Size/Type Workload OS Location worker-1 DigitalOcean 10.8.0.13 138.197.68.229 s-2vcpu-4gb tools Ubuntu 22.04 NYC3 worker-2 DigitalOcean 10.8.0.14 165.227.219.199 s-2vcpu-4gb tools Ubuntu 22.04 NYC3 worker-3 Linode 10.8.0.15 96.126.106.49 g6-standard-2 misc Ubuntu 22.04 US-East <p>Resources per Worker: - 2 vCPUs - 4 GB RAM - 80 GB SSD</p>"},{"location":"#node-labels-taints","title":"Node Labels &amp; Taints","text":""},{"location":"#tools-workers-worker-1-worker-2","title":"Tools Workers (worker-1, worker-2)","text":"<pre><code>Labels:\n  workload: tools\n\nTaints:\n  - key: workload\n    value: tools\n    effect: NoSchedule\n</code></pre> <p>Purpose: Dedicated to development tools (ArgoCD, CI/CD, monitoring, etc.)</p>"},{"location":"#misc-worker-worker-3","title":"Misc Worker (worker-3)","text":"<pre><code>Labels:\n  workload: misc\n\nTaints:\n  - key: workload\n    value: misc\n    effect: NoSchedule\n</code></pre> <p>Purpose: Miscellaneous workloads and experimental deployments</p>"},{"location":"#networking-vpn","title":"Networking &amp; VPN","text":""},{"location":"#wireguard-vpn-configuration","title":"WireGuard VPN Configuration","text":"<p>All nodes are connected via a full-mesh WireGuard VPN:</p> <ul> <li>VPN Server: 3.93.242.31 (AWS EC2 - Amazon Linux 2023)</li> <li>VPN Network: 10.8.0.0/24</li> <li>VPN Interface: wg0</li> <li>Port: 51820 (UDP)</li> <li>Encryption: ChaCha20-Poly1305</li> </ul>"},{"location":"#vpn-ip-allocation","title":"VPN IP Allocation","text":"IP Range Purpose 10.8.0.1 VPN Server 10.8.0.2 Your client machine 10.8.0.10-12 Kubernetes master nodes 10.8.0.13-15 Kubernetes worker nodes"},{"location":"#network-topology","title":"Network Topology","text":"<ul> <li>Full Mesh: Each Kubernetes node has direct WireGuard tunnels to:</li> <li>All other Kubernetes nodes (5 peers)</li> <li>VPN server (1 peer)</li> <li> <p>Total: 6 WireGuard peers per node</p> </li> <li> <p>Persistent Keepalive: 25 seconds (maintains NAT traversal)</p> </li> <li>Allowed Networks:</li> <li><code>10.8.0.0/24</code> - VPN network</li> <li><code>10.0.0.0/16</code> - Additional private network</li> <li><code>10.11.0.0/16</code> - Reserved range</li> <li><code>10.20.0.0/24</code>, <code>10.21.0.0/24</code>, <code>10.22.0.0/24</code> - Application subnets</li> </ul>"},{"location":"#dns-configuration","title":"DNS Configuration","text":"<p>All cluster DNS records point to VPN private IPs:</p> DNS Record IP Purpose api.chalkan3.com.br 10.8.0.10 Kubernetes API argocd.kube.chalkan3.com.br 10.8.0.13 ArgoCD UI"},{"location":"#node-configuration","title":"Node Configuration","text":""},{"location":"#pre-installed-software","title":"Pre-installed Software","text":"<p>All nodes come with the following pre-installed:</p> <ul> <li>Docker (via get.docker.sh)</li> <li>WireGuard + wireguard-tools</li> <li>Kernel Modules: br_netfilter, overlay</li> <li>NFS Client (for persistent volumes)</li> <li>sysctl Configurations: <pre><code>net.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.ipv4.ip_forward = 1\n</code></pre></li> </ul>"},{"location":"#ssh-access","title":"SSH Access","text":"<p>SSH Key: <code>~/.ssh/kubernetes-clusters/production.pem</code></p> <pre><code># Access master nodes\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.10  # master-1\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.11  # master-2\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.12  # master-3\n\n# Access worker nodes\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.13  # worker-1\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.14  # worker-2\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.15  # worker-3\n</code></pre> <p>Shell Shortcuts: <pre><code># These functions are available in ~/.zsh/functions.zsh\nssh-k8s-master-1   # SSH to master-1\nssh-k8s-master-2   # SSH to master-2\nssh-k8s-master-3   # SSH to master-3\nssh-k8s-worker-1   # SSH to worker-1\nssh-k8s-worker-2   # SSH to worker-2\nssh-k8s-worker-3   # SSH to worker-3\n\n# List all VPN hosts\nvpn-hosts\n</code></pre></p>"},{"location":"#deployed-services","title":"Deployed Services","text":""},{"location":"#system-services","title":"System Services","text":""},{"location":"#calico-cni","title":"Calico CNI","text":"<ul> <li>Namespace: <code>calico-system</code>, <code>tigera-operator</code></li> <li>Purpose: Pod networking and network policies</li> <li>CIDR: Automatic IPAM</li> </ul>"},{"location":"#nginx-ingress-controller","title":"Nginx Ingress Controller","text":"<ul> <li>Namespace: <code>ingress-nginx</code></li> <li>Version: v1.11.1</li> <li>Type: DaemonSet with hostPort</li> <li>Ports:</li> <li>HTTP: 80 (hostPort)</li> <li>HTTPS: 443 (hostPort)</li> <li>Features:</li> <li>SSL Passthrough: \u2705 Enabled</li> <li>Default Backend: \u2705</li> <li>Admission Webhook: \u2705</li> </ul>"},{"location":"#application-services","title":"Application Services","text":""},{"location":"#argocd","title":"ArgoCD","text":"<ul> <li>Namespace: <code>argocd</code></li> <li>Version: v3.1.9</li> <li>Access: https://argocd.kube.chalkan3.com.br</li> <li>Service Type: ClusterIP (VPN-only access)</li> <li>Ingress: Nginx with SSL passthrough</li> <li>Authentication:</li> <li>Username: <code>admin</code></li> <li>Password: <code>w-13KcdiqsQwruLs</code></li> </ul> <p>ArgoCD CLI: <pre><code># Login\nargocd login argocd.kube.chalkan3.com.br \\\n  --username admin \\\n  --password w-13KcdiqsQwruLs \\\n  --insecure\n\n# Check status\nargocd app list\n</code></pre></p>"},{"location":"#access-authentication","title":"Access &amp; Authentication","text":""},{"location":"#kubernetes-api-access","title":"Kubernetes API Access","text":"<p>Kubeconfig Location: <code>~/.kube/config</code></p> <p>API Server: https://api.chalkan3.com.br:6443</p> <pre><code># Verify access\nkubectl cluster-info\nkubectl get nodes\nkubectl get pods --all-namespaces\n</code></pre>"},{"location":"#vpn-connection","title":"VPN Connection","text":"<p>VPN Client Configuration: <pre><code># Check VPN status\nsudo wg show\n\n# VPN should show:\n# - Interface: utun4\n# - Your IP: 10.8.0.2\n# - Peer: VPN Server (3.93.242.31)\n# - Allowed IPs: 10.8.0.0/24, 10.0.0.0/16, etc.\n</code></pre></p> <p>Testing VPN Connectivity: <pre><code># Ping Kubernetes nodes\nping 10.8.0.10  # master-1\nping 10.8.0.13  # worker-1\n\n# Should see ~140ms latency (via VPN gateway)\n</code></pre></p>"},{"location":"#service-access","title":"Service Access","text":"<p>All services are accessible only via VPN:</p> Service URL/Endpoint Port Protocol Kubernetes API https://api.chalkan3.com.br:6443 6443 HTTPS ArgoCD UI https://argocd.kube.chalkan3.com.br 443 HTTPS kubectl Via kubeconfig 6443 HTTPS"},{"location":"#deployment-guide","title":"Deployment Guide","text":""},{"location":"#deploying-to-tools-workers","title":"Deploying to Tools Workers","text":"<p>For services that should run on <code>tools</code> workers (worker-1, worker-2):</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-tool\n  namespace: tools\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-tool\n  template:\n    metadata:\n      labels:\n        app: my-tool\n    spec:\n      # Node selector to target tools workers\n      nodeSelector:\n        workload: tools\n\n      # Toleration to allow scheduling on tainted nodes\n      tolerations:\n      - key: workload\n        operator: Equal\n        value: tools\n        effect: NoSchedule\n\n      containers:\n      - name: my-tool\n        image: my-tool:latest\n        ports:\n        - containerPort: 8080\n</code></pre>"},{"location":"#deploying-to-misc-worker","title":"Deploying to Misc Worker","text":"<p>For miscellaneous workloads (worker-3):</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-misc-app\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: my-misc-app\n  template:\n    metadata:\n      labels:\n        app: my-misc-app\n    spec:\n      # Node selector to target misc worker\n      nodeSelector:\n        workload: misc\n\n      # Toleration for misc taint\n      tolerations:\n      - key: workload\n        operator: Equal\n        value: misc\n        effect: NoSchedule\n\n      containers:\n      - name: my-misc-app\n        image: my-app:latest\n        ports:\n        - containerPort: 3000\n</code></pre>"},{"location":"#exposing-services-via-ingress","title":"Exposing Services via Ingress","text":"<p>Create an Ingress to expose your service via HTTPS:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-service-ingress\n  namespace: tools\n  annotations:\n    # Use Nginx ingress controller\n    kubernetes.io/ingress.class: nginx\n    # For HTTPS backends\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n    # For SSL passthrough (if needed)\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: myservice.kube.chalkan3.com.br\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-service\n            port:\n              number: 443\n</code></pre> <p>Don't forget to add DNS record: <pre><code>doctl compute domain records create chalkan3.com.br \\\n  --record-type A \\\n  --record-name myservice.kube \\\n  --record-data 10.8.0.13 \\\n  --record-ttl 300\n</code></pre></p>"},{"location":"#maintenance-operations","title":"Maintenance &amp; Operations","text":""},{"location":"#cluster-management","title":"Cluster Management","text":""},{"location":"#check-cluster-health","title":"Check Cluster Health","text":"<pre><code># Node status\nkubectl get nodes -o wide\n\n# Pod status across all namespaces\nkubectl get pods --all-namespaces\n\n# Component status\nkubectl get componentstatuses\n\n# Cluster info\nkubectl cluster-info\n</code></pre>"},{"location":"#view-node-resources","title":"View Node Resources","text":"<pre><code># Node resource usage\nkubectl top nodes\n\n# Pod resource usage\nkubectl top pods --all-namespaces\n</code></pre>"},{"location":"#drain-a-node-for-maintenance","title":"Drain a Node (for maintenance)","text":"<pre><code># Safely evict all pods from a node\nkubectl drain worker-1 --ignore-daemonsets --delete-emptydir-data\n\n# Mark node as schedulable again\nkubectl uncordon worker-1\n</code></pre>"},{"location":"#pulumi-operations","title":"Pulumi Operations","text":""},{"location":"#view-stack-outputs","title":"View Stack Outputs","text":"<pre><code>cd ~/.projects/do-droplet-create\n\n# List all outputs\npulumi stack output\n\n# Get kubeconfig\npulumi stack output kubeConfig --show-secrets\n\n# Get SSH key\npulumi stack output ssh_private_key --show-secrets\n\n# Get connection instructions\npulumi stack output connectionInstructions\n</code></pre>"},{"location":"#update-infrastructure","title":"Update Infrastructure","text":"<pre><code># Preview changes\npulumi preview\n\n# Apply changes\npulumi up\n\n# Destroy entire cluster (\u26a0\ufe0f DANGEROUS)\npulumi destroy\n</code></pre>"},{"location":"#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"#backup-etcd","title":"Backup etcd","text":"<pre><code># SSH to any master node\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.10\n\n# Create etcd snapshot\nsudo rke2 etcd-snapshot save --name manual-backup-$(date +%Y%m%d-%H%M%S)\n\n# List snapshots\nsudo rke2 etcd-snapshot list\n</code></pre>"},{"location":"#backup-kubeconfig","title":"Backup Kubeconfig","text":"<pre><code># Local backup\ncp ~/.kube/config ~/.kube/config.backup-$(date +%Y%m%d)\n\n# From Pulumi\npulumi stack output kubeConfig --show-secrets &gt; ~/kubeconfig-backup-$(date +%Y%m%d).yaml\n</code></pre>"},{"location":"#monitoring-logs","title":"Monitoring &amp; Logs","text":""},{"location":"#view-pod-logs","title":"View Pod Logs","text":"<pre><code># Follow logs\nkubectl logs -f &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Previous container logs (if crashed)\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --previous\n\n# All pods in deployment\nkubectl logs -l app=my-app -n tools --tail=100\n</code></pre>"},{"location":"#view-events","title":"View Events","text":"<pre><code># Cluster-wide events\nkubectl get events --all-namespaces --sort-by='.lastTimestamp'\n\n# Events in specific namespace\nkubectl get events -n argocd\n</code></pre>"},{"location":"#describe-resources","title":"Describe Resources","text":"<pre><code># Detailed node info\nkubectl describe node worker-1\n\n# Detailed pod info\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"#troubleshooting","title":"Troubleshooting","text":""},{"location":"#common-issues","title":"Common Issues","text":""},{"location":"#1-cannot-access-cluster","title":"1. Cannot Access Cluster","text":"<p>Symptoms: <code>kubectl</code> commands timeout or fail</p> <p>Troubleshooting: <pre><code># Check VPN connectivity\nsudo wg show\nping 10.8.0.10\n\n# Verify kubeconfig\nkubectl config current-context\nkubectl config view\n\n# Test API server\ncurl -k https://api.chalkan3.com.br:6443\n</code></pre></p> <p>Solution: - Ensure VPN is connected - Verify <code>~/.kube/config</code> is correct - Check VPN allowed IPs include <code>10.8.0.0/24</code></p>"},{"location":"#2-pods-not-scheduling","title":"2. Pods Not Scheduling","text":"<p>Symptoms: Pods stuck in <code>Pending</code> state</p> <p>Troubleshooting: <pre><code># Check pod status\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Check node taints\nkubectl describe node worker-1 | grep Taints\n\n# Check pod tolerations\nkubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o yaml | grep -A5 tolerations\n</code></pre></p> <p>Solution: - Add correct <code>nodeSelector</code> and <code>tolerations</code> to pod spec - Verify worker nodes have capacity - Check if taints are preventing scheduling</p>"},{"location":"#3-ingress-not-working","title":"3. Ingress Not Working","text":"<p>Symptoms: Cannot access service via domain</p> <p>Troubleshooting: <pre><code># Check Ingress status\nkubectl get ingress -n &lt;namespace&gt;\nkubectl describe ingress &lt;ingress-name&gt; -n &lt;namespace&gt;\n\n# Check Ingress Controller\nkubectl get pods -n ingress-nginx\n\n# Check DNS resolution\nhost myservice.kube.chalkan3.com.br\n\n# Test direct access to NodePort\ncurl -k https://10.8.0.13:31328\n</code></pre></p> <p>Solution: - Verify DNS points to correct VPN IP - Check Ingress annotations are correct - Ensure service is running: <code>kubectl get svc -n &lt;namespace&gt;</code> - Verify Nginx Ingress Controller is healthy</p>"},{"location":"#4-vpn-connectivity-issues","title":"4. VPN Connectivity Issues","text":"<p>Symptoms: Cannot ping nodes at 10.8.0.x</p> <p>Troubleshooting: <pre><code># Check WireGuard status\nsudo wg show\n\n# Check routes\nnetstat -rn | grep 10.8\n\n# Ping VPN server\nping 10.8.0.1\n\n# Check WireGuard on nodes\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.10 \"sudo wg show\"\n</code></pre></p> <p>Solution: - Restart WireGuard: <code>sudo systemctl restart wg-quick@wg0</code> (on VPN server) - Verify peers are configured on both sides - Check firewall allows UDP port 51820</p>"},{"location":"#5-node-not-ready","title":"5. Node Not Ready","text":"<p>Symptoms: Node shows <code>NotReady</code> status</p> <p>Troubleshooting: <pre><code># Check node status\nkubectl describe node &lt;node-name&gt;\n\n# SSH to node and check kubelet\nssh -i ~/.ssh/kubernetes-clusters/production.pem root@&lt;node-ip&gt;\nsudo systemctl status rke2-server  # for masters\nsudo systemctl status rke2-agent   # for workers\n\n# Check logs\nsudo journalctl -u rke2-agent -f\n</code></pre></p> <p>Solution: - Restart RKE2 service - Check disk space: <code>df -h</code> - Verify network connectivity - Check container runtime: <code>sudo crictl ps</code></p>"},{"location":"#getting-help","title":"Getting Help","text":"<p>Useful Commands: <pre><code># Cluster diagnostics\nkubectl cluster-info dump &gt; cluster-dump.txt\n\n# Node diagnostics\nkubectl get nodes -o yaml &gt; nodes.yaml\n\n# Pod diagnostics\nkubectl get pods --all-namespaces -o wide &gt; pods.txt\n\n# Events\nkubectl get events --all-namespaces &gt; events.txt\n</code></pre></p> <p>Log Locations on Nodes: - RKE2 Server: <code>/var/lib/rancher/rke2/agent/logs/</code> - Kubelet: <code>journalctl -u rke2-agent</code> - Container logs: <code>sudo crictl logs &lt;container-id&gt;</code></p>"},{"location":"#security-considerations","title":"Security Considerations","text":""},{"location":"#network-security","title":"Network Security","text":"<ul> <li>\u2705 All cluster communication via WireGuard VPN (encrypted)</li> <li>\u2705 No public exposure of services</li> <li>\u2705 DNS points to private IPs only</li> <li>\u2705 Ingress Controller uses SSL/TLS</li> </ul>"},{"location":"#access-control","title":"Access Control","text":"<ul> <li>\u2705 SSH key-based authentication only</li> <li>\u2705 Kubernetes RBAC enabled</li> <li>\u2705 ArgoCD with authentication required</li> <li>\u2705 API server certificate-based auth</li> </ul>"},{"location":"#best-practices","title":"Best Practices","text":"<ol> <li>Never commit secrets to Git - Use ArgoCD with sealed secrets or external secret management</li> <li>Rotate credentials regularly - Change ArgoCD admin password, regenerate SSH keys</li> <li>Monitor cluster activity - Review logs and events regularly</li> <li>Keep nodes updated - Apply security patches to Ubuntu and Kubernetes</li> <li>Backup regularly - Automated etcd snapshots and config backups</li> </ol>"},{"location":"#quick-reference","title":"Quick Reference","text":""},{"location":"#essential-commands","title":"Essential Commands","text":"<pre><code># Cluster status\nkubectl get nodes\nkubectl get pods --all-namespaces\n\n# Deploy application\nkubectl apply -f deployment.yaml\n\n# Check logs\nkubectl logs -f &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Execute in pod\nkubectl exec -it &lt;pod-name&gt; -n &lt;namespace&gt; -- /bin/bash\n\n# Port forward\nkubectl port-forward -n &lt;namespace&gt; svc/&lt;service&gt; 8080:80\n\n# Scale deployment\nkubectl scale deployment &lt;name&gt; --replicas=3 -n &lt;namespace&gt;\n\n# Delete resources\nkubectl delete -f deployment.yaml\n</code></pre>"},{"location":"#important-paths","title":"Important Paths","text":"<ul> <li>Kubeconfig: <code>~/.kube/config</code></li> <li>SSH Key: <code>~/.ssh/kubernetes-clusters/production.pem</code></li> <li>Pulumi Project: <code>~/.projects/do-droplet-create</code></li> <li>Shell Functions: <code>~/.zsh/functions.zsh</code></li> </ul>"},{"location":"#important-urls","title":"Important URLs","text":"<ul> <li>API Server: https://api.chalkan3.com.br:6443</li> <li>ArgoCD: https://argocd.kube.chalkan3.com.br</li> <li>VPN Server: 3.93.242.31 (10.8.0.1)</li> </ul>"},{"location":"#appendix","title":"Appendix","text":""},{"location":"#cluster-specifications-summary","title":"Cluster Specifications Summary","text":"Component Details Kubernetes Version v1.33.5+rke2r1 Distribution RKE2 Container Runtime containerd 2.1.4-k3s2 CNI Calico Ingress Nginx v1.11.1 GitOps ArgoCD v3.1.9 Total Nodes 6 (3 masters + 3 workers) Total vCPUs 12 vCPUs Total RAM 24 GB Total Storage ~480 GB SSD Cloud Providers DigitalOcean (3 nodes) + Linode (3 nodes) Network WireGuard VPN full-mesh"},{"location":"#change-log","title":"Change Log","text":"Date Change Author 2025-10-18 Initial cluster deployment Claude 2025-10-18 ArgoCD installation and configuration Claude 2025-10-18 VPN mesh configuration with all nodes Claude 2025-10-18 Worker node labels and taints (tools/misc) Claude 2025-10-18 Nginx Ingress Controller with hostPort 80/443 Claude <p>Documentation Version: 1.0 Last Updated: October 18, 2025 Maintained By: Infrastructure Team</p>"},{"location":"INDEX/","title":"\ud83e\udda5 Welcome to Sloth Kubernetes","text":"**Deploy Kubernetes clusters across multiple clouds** ***Slowly, but surely*** \ud83d\udc0c  [![Go Version](https://img.shields.io/badge/Go-1.23+-00ADD8?style=for-the-badge&amp;logo=go)](https://go.dev/) [![Test Coverage](https://img.shields.io/badge/coverage-90%25-brightgreen?style=for-the-badge)](contributing/testing.md) [![License](https://img.shields.io/badge/license-MIT-blue.svg?style=for-the-badge)](LICENSE.md)  [Get Started](getting-started/quickstart.md){ .md-button .md-button--primary } [View on GitHub](https://github.com/yourusername/sloth-kubernetes){ .md-button }"},{"location":"INDEX/#what-is-sloth-kubernetes","title":"\ud83c\udf1f What is Sloth Kubernetes?","text":"<p>Sloth Kubernetes is a single-binary CLI tool that deploys production-ready Kubernetes clusters across multiple cloud providers with zero external dependencies. No Pulumi CLI, no Terraform, no kubectl required for deployment\u2014just one lazy sloth doing all the heavy lifting! \ud83e\udda5\ud83d\udcaa</p> <p>The Sloth Philosophy</p> <p>Why rush? Good things take time. We'll get there... eventually. \ud83e\udda5</p> <ul> <li> <p>\ud83d\ude80 Zero Dependencies</p> <p>Everything you need in one binary. No Pulumi CLI, no complex setup. Just download and deploy! \ud83e\udda5</p> <p> Installation</p> </li> <li> <p>\ud83c\udf0d True Multi-Cloud</p> <p>Deploy across DigitalOcean and Linode. Your cluster, your choice, multiple clouds! \ud83e\udda5</p> <p> Multi-Cloud Guide</p> </li> <li> <p>\ud83d\udd10 Secure by Default</p> <p>WireGuard VPN mesh, encrypted secrets, CIS benchmarks. Security while you sleep! \ud83d\ude34\ud83e\udda5</p> <p> Security</p> </li> <li> <p>\ud83c\udf33 GitOps Native</p> <p>ArgoCD auto-bootstrap, Git as source of truth. Set it and forget it! \ud83e\udda5</p> <p> GitOps</p> </li> </ul>"},{"location":"INDEX/#quick-start","title":"\u26a1 Quick Start","text":"<p>3 Minutes to Production Cluster</p> <p>Have a production-ready cluster in the time it takes to make coffee! \u2615\ud83e\udda5</p> <pre><code># Step 1: Download (pick your platform)\ncurl -L https://github.com/user/sloth-kubernetes/releases/latest/download/sloth-kubernetes -o sloth-kubernetes\nchmod +x sloth-kubernetes\n\n# Step 2: Create config\ncat &gt; cluster.yaml &lt;&lt;EOF\napiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: my-cluster\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: \\${DIGITALOCEAN_TOKEN}\n  kubernetes:\n    version: v1.28.5+rke2r1\n  nodePools:\n    - name: masters\n      count: 3\n      roles: [master]\nEOF\n\n# Step 3: Deploy! \ud83e\udda5\nexport DIGITALOCEAN_TOKEN=\"your-token\"\n./sloth-kubernetes deploy --config cluster.yaml\n\n# Step 4: Access your cluster\n./sloth-kubernetes kubeconfig &gt; ~/.kube/config\nkubectl get nodes\n</code></pre> <p>Full Quick Start Guide \u2192</p>"},{"location":"INDEX/#why-sloth-kubernetes","title":"\ud83c\udfaf Why Sloth Kubernetes?","text":""},{"location":"INDEX/#traditional-vs-sloth-way","title":"Traditional vs. Sloth Way","text":"Aspect Traditional Sloth Way \ud83e\udda5 Installation Multiple CLIs + tools Single binary Dependencies Pulumi + kubectl + more None Setup Time 30-60 minutes 3-5 minutes Multi-Cloud Complex manual Built-in VPN Setup Hours of config Automatic Learning Curve Steep \u26f0\ufe0f Gentle \ud83e\udda5 <p>Ancient Sloth Proverb</p> <p>\"The best time to deploy was yesterday. The second best time is now... but take your time!\" \ud83e\udda5</p>"},{"location":"INDEX/#key-features","title":"\ud83d\ude80 Key Features","text":""},{"location":"INDEX/#single-binary-simplicity","title":"\ud83c\udfaf Single Binary Simplicity","text":"<p>Everything embedded in one binary:</p> <ul> <li>\u2705 Pulumi Automation API (no CLI needed)</li> <li>\u2705 State management</li> <li>\u2705 VPN configuration</li> <li>\u2705 GitOps bootstrap</li> <li>\u2705 Kubeconfig generation</li> </ul>"},{"location":"INDEX/#multi-cloud-support","title":"\ud83c\udf0d Multi-Cloud Support","text":"<pre><code>        \ud83e\udda5 Your Kubernetes Cluster \ud83e\udda5\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   DigitalOcean     \u2502  \u2502      Linode        \u2502\n\u2502   Region: NYC3     \u2502  \u2502  Region: US-East   \u2502\n\u2502                    \u2502  \u2502                    \u2502\n\u2502 \u2022 Master 1    \ud83e\udda5   \u2502  \u2502 \u2022 Master 2    \ud83e\udda5   \u2502\n\u2502 \u2022 Worker 1    \ud83e\udda5   \u2502  \u2502 \u2022 Master 3    \ud83e\udda5   \u2502\n\u2502 \u2022 Worker 2    \ud83e\udda5   \u2502  \u2502 \u2022 Worker 3    \ud83e\udda5   \u2502\n\u2502                    \u2502  \u2502                    \u2502\n\u2502 VPC: 10.10.0.0/16  \u2502  \u2502 VPC: 10.11.0.0/16  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                        \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba VPN \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             WireGuard \ud83d\udd10\n            10.8.0.0/24\n</code></pre>"},{"location":"INDEX/#automated-security","title":"\ud83d\udd10 Automated Security","text":"<ul> <li>WireGuard VPN mesh (automatic setup)</li> <li>Encrypted secrets at rest</li> <li>CIS benchmark compliance</li> <li>Pod security policies</li> <li>Network policies</li> <li>Bastion host support</li> </ul>"},{"location":"INDEX/#gitops-ready","title":"\ud83c\udf33 GitOps Ready","text":"<pre><code># Deploy cluster\nsloth-kubernetes deploy --config cluster.yaml\n\n# Bootstrap ArgoCD\nsloth-kubernetes addons bootstrap \\\n  --repo https://github.com/yourorg/k8s-gitops\n\n# Everything auto-syncs from Git! \ud83e\udda5\ud83c\udf33\n</code></pre>"},{"location":"INDEX/#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li> <p>\ud83d\udcd6 Getting Started</p> <p>New to Sloth? Start here! \ud83e\udda5</p> <ul> <li>Installation</li> <li>Quick Start</li> <li>First Cluster</li> </ul> </li> <li> <p>\ud83d\udcbb User Guide</p> <p>Day-to-day operations \ud83e\udda5</p> <ul> <li>CLI Reference</li> <li>Deploy</li> <li>Manage Nodes</li> <li>VPN Management</li> </ul> </li> <li> <p>\u2699\ufe0f Configuration</p> <p>Configure your cluster \ud83e\udda5</p> <ul> <li>File Structure</li> <li>Providers</li> <li>Network</li> <li>Examples</li> </ul> </li> <li> <p>\ud83c\udf93 Advanced</p> <p>Pro tips and tricks \ud83e\udda5</p> <ul> <li>Architecture</li> <li>Multi-Cloud</li> <li>State Management</li> <li>GitOps</li> </ul> </li> </ul>"},{"location":"INDEX/#real-world-example","title":"\ud83e\udda5 Real-World Example","text":"<p>Production-grade multi-cloud HA cluster:</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: production-ha\n  labels:\n    environment: production\n\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.10.0.0/16\n\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}\n      region: us-east\n      vpc:\n        create: true\n        cidr: 10.11.0.0/16\n\n  network:\n    wireguard:\n      create: true  # \ud83e\udda5 Auto-create VPN!\n      meshNetworking: true\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n    rke2:\n      secretsEncryption: true\n      snapshotScheduleCron: \"0 */12 * * *\"\n      profiles:\n        - cis-1.6\n\n  nodePools:\n    do-masters:\n      provider: digitalocean\n      count: 1\n      roles: [master]\n      size: s-2vcpu-4gb\n\n    linode-masters:\n      provider: linode\n      count: 2  # Odd number for quorum\n      roles: [master]\n      size: g6-standard-2\n\n    do-workers:\n      provider: digitalocean\n      count: 2\n      roles: [worker]\n      size: s-2vcpu-4gb\n\n    linode-workers:\n      provider: linode\n      count: 2\n      roles: [worker]\n      size: g6-standard-2\n\n  security:\n    bastion:\n      enabled: true\n    podSecurity:\n      enabled: true\n\n  addons:\n    gitops:\n      enabled: true\n      repository: https://github.com/yourorg/k8s-gitops\n</code></pre> <p>Deploy in One Command</p> <pre><code>sloth-kubernetes deploy --config production-ha.yaml\n</code></pre> <p>The sloth will: \ud83e\udda5</p> <ul> <li>Create VPCs on both clouds</li> <li>Deploy WireGuard VPN server</li> <li>Provision 7 nodes (3 masters, 4 workers)</li> <li>Install RKE2 Kubernetes</li> <li>Configure encrypted mesh</li> <li>Bootstrap ArgoCD</li> <li>Set up automated backups</li> <li>Apply security policies</li> </ul> <p>Time: 8-10 minutes \u2615</p>"},{"location":"INDEX/#what-makes-us-different","title":"\ud83c\udf93 What Makes Us Different?","text":"<p>\u2705 No External Dependencies - One binary, that's it \u2705 Multi-Cloud Native - Not bolted on, built in \u2705 Auto VPN - WireGuard mesh configured automatically \u2705 GitOps First - Bootstrap in one command \u2705 Production Ready - HA, backups, security hardening \u2705 Simple - Kubernetes-style YAML config \u2705 Fast - Deploy in 5-10 minutes \u2705 Sloth Approved - Slow is smooth, smooth is fast \ud83e\udda5</p>"},{"location":"INDEX/#community","title":"\ud83c\udf1f Community","text":"<p>Join the sloth family! \ud83e\udda5</p> <ul> <li> GitHub - Star us!</li> <li> Slack - Chat with us!</li> <li> Twitter - Follow for updates!</li> <li> Email - Get help!</li> </ul>"},{"location":"INDEX/#ready","title":"\ud83e\udda5 Ready?","text":"<p>Take it slow, take it steady, take it with a sloth!</p>   [Install Now](getting-started/installation.md){ .md-button .md-button--primary .md-button--lg } [Quick Start](getting-started/quickstart.md){ .md-button .md-button--lg } [View Examples](configuration/examples.md){ .md-button .md-button--lg }  ---  **Made with \ud83e\udda5 and \u2764\ufe0f by the Sloth Kubernetes community**"},{"location":"NETWORK_DIAGRAM/","title":"Network Architecture Diagram","text":""},{"location":"NETWORK_DIAGRAM/#complete-network-topology","title":"Complete Network Topology","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Internet / Public Network                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                    \u2502                    \u2502\n        \u2502                    \u2502                    \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n   \u2502   DO    \u2502          \u2502 Linode  \u2502         \u2502   AWS   \u2502\n   \u2502  Nodes  \u2502          \u2502  Nodes  \u2502         \u2502   VPN   \u2502\n   \u2502         \u2502          \u2502         \u2502         \u2502  Server \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n        \u2502                    \u2502                    \u2502\n        \u2502                    \u2502                    \u2502\n        \u2502   WireGuard VPN Mesh (10.8.0.0/24)    \u2502\n        \u2502                    \u2502                    \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                                                  \u2502\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n\u2502               WireGuard VPN Network (10.8.0.0/24)           \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502VPN Server\u2502  \u2502  Client  \u2502  \u2502 Master 1 \u2502  \u2502 Master 2 \u2502   \u2502\n\u2502  \u250210.8.0.1  \u2502  \u250210.8.0.2  \u2502  \u250210.8.0.10 \u2502  \u250210.8.0.11 \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Master 3 \u2502  \u2502 Worker 1 \u2502  \u2502 Worker 2 \u2502  \u2502 Worker 3 \u2502   \u2502\n\u2502  \u250210.8.0.12 \u2502  \u250210.8.0.13 \u2502  \u250210.8.0.14 \u2502  \u250210.8.0.15 \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#kubernetes-cluster-network-detail","title":"Kubernetes Cluster Network Detail","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Kubernetes Cluster                                  \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                      Control Plane (HA)                              \u2502   \u2502\n\u2502  \u2502                                                                       \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502   \u2502\n\u2502  \u2502  \u2502    master-1      \u2502  \u2502    master-2      \u2502  \u2502    master-3      \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502   10.8.0.10      \u2502  \u2502   10.8.0.11      \u2502  \u2502   10.8.0.12      \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 API Server   \u2502 \u2502  \u2502 \u2502 API Server   \u2502 \u2502  \u2502 \u2502 API Server   \u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 :6443        \u2502 \u2502  \u2502 \u2502 :6443        \u2502 \u2502  \u2502 \u2502 :6443        \u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 etcd         \u2502\u25c4\u253c\u2500\u2500\u253c\u2500\u2524 etcd         \u2502\u25c4\u253c\u2500\u2500\u253c\u2500\u2524 etcd         \u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 :2379,2380   \u2502 \u2502  \u2502 \u2502 :2379,2380   \u2502 \u2502  \u2502 \u2502 :2379,2380   \u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 Scheduler    \u2502 \u2502  \u2502 \u2502 Scheduler    \u2502 \u2502  \u2502 \u2502 Scheduler    \u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502Controller Mgr\u2502 \u2502  \u2502 \u2502Controller Mgr\u2502 \u2502  \u2502 \u2502Controller Mgr\u2502 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                        \u2502\n\u2502                                      \u2502 Calico CNI                             \u2502\n\u2502                                      \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                         Worker Nodes                                   \u2502   \u2502\n\u2502  \u2502                                                                         \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502   \u2502\n\u2502  \u2502  \u2502    worker-1      \u2502  \u2502    worker-2      \u2502  \u2502    worker-3      \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502   10.8.0.13      \u2502  \u2502   10.8.0.14      \u2502  \u2502   10.8.0.15      \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502   (tools)        \u2502  \u2502   (tools)        \u2502  \u2502   (misc)         \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502   kubelet    \u2502 \u2502  \u2502 \u2502   kubelet    \u2502 \u2502  \u2502 \u2502   kubelet    \u2502 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502 containerd   \u2502 \u2502  \u2502 \u2502 containerd   \u2502 \u2502  \u2502 \u2502 containerd   \u2502 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502Nginx Ingress \u2502 \u2502  \u2502 \u2502Nginx Ingress \u2502 \u2502  \u2502 \u2502Nginx Ingress \u2502 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2502   :80,:443   \u2502 \u2502  \u2502 \u2502   :80,:443   \u2502 \u2502  \u2502 \u2502   :80,:443   \u2502 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502                  \u2502  \u2502                  \u2502  \u2502                  \u2502    \u2502   \u2502\n\u2502  \u2502  \u2502  [Pods: Tools]   \u2502  \u2502  [Pods: Tools]   \u2502  \u2502  [Pods: Misc]    \u2502    \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#traffic-flow-diagram","title":"Traffic Flow Diagram","text":""},{"location":"NETWORK_DIAGRAM/#external-user-argocd-via-vpn","title":"External User \u2192 ArgoCD (via VPN)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              \u2502\n\u2502  Your Client \u2502\n\u2502  (10.8.0.2)  \u2502\n\u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 1. VPN connection via WireGuard\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              \u2502\n\u2502  VPN Server  \u2502\n\u2502  (10.8.0.1)  \u2502\n\u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 2. Route to K8s worker\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  worker-1 (10.8.0.13)                \u2502\n\u2502                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Nginx Ingress Controller      \u2502  \u2502\n\u2502  \u2502  Listening on :443 (hostPort)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502               \u2502 3. Route based on    \u2502\n\u2502               \u2502    Host header       \u2502\n\u2502               \u25bc                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Ingress Resource              \u2502  \u2502\n\u2502  \u2502  Host: argocd.kube.*           \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502               \u2502 4. Forward to        \u2502\n\u2502               \u2502    ClusterIP         \u2502\n\u2502               \u25bc                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  ArgoCD Service (ClusterIP)    \u2502  \u2502\n\u2502  \u2502  Port: 443                     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502               \u2502 5. Load balance      \u2502\n\u2502               \u2502    to pods           \u2502\n\u2502               \u25bc                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  ArgoCD Server Pods            \u2502  \u2502\n\u2502  \u2502  Port: 8080                    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#kubectl-kubernetes-api","title":"kubectl \u2192 Kubernetes API","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              \u2502\n\u2502  Your Client \u2502\n\u2502  (10.8.0.2)  \u2502\n\u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 1. VPN connection\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              \u2502\n\u2502  VPN Server  \u2502\n\u2502  (10.8.0.1)  \u2502\n\u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 2. Route to master\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  master-1 (10.8.0.10)        \u2502\n\u2502                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  API Server            \u2502  \u2502\n\u2502  \u2502  Port: 6443            \u2502  \u2502\n\u2502  \u2502  (TLS encrypted)       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#wireguard-peer-connections","title":"WireGuard Peer Connections","text":""},{"location":"NETWORK_DIAGRAM/#full-mesh-topology","title":"Full Mesh Topology","text":"<pre><code>Each node connects to every other node:\n\nmaster-1 (10.8.0.10) \u2500\u2500\u252c\u2500\u2500 VPN Server (10.8.0.1)\n                       \u251c\u2500\u2500 master-2 (10.8.0.11)\n                       \u251c\u2500\u2500 master-3 (10.8.0.12)\n                       \u251c\u2500\u2500 worker-1 (10.8.0.13)\n                       \u251c\u2500\u2500 worker-2 (10.8.0.14)\n                       \u2514\u2500\u2500 worker-3 (10.8.0.15)\n\nmaster-2 (10.8.0.11) \u2500\u2500\u252c\u2500\u2500 VPN Server (10.8.0.1)\n                       \u251c\u2500\u2500 master-1 (10.8.0.10)\n                       \u251c\u2500\u2500 master-3 (10.8.0.12)\n                       \u251c\u2500\u2500 worker-1 (10.8.0.13)\n                       \u251c\u2500\u2500 worker-2 (10.8.0.14)\n                       \u2514\u2500\u2500 worker-3 (10.8.0.15)\n\n... (similar for all nodes)\n\nTotal tunnels: 6 peers per Kubernetes node\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#network-latency","title":"Network Latency","text":"<pre><code>Your Client (10.8.0.2) \u2192 VPN Server (10.8.0.1)\n    \u2502\n    \u251c\u2500&gt; master-1 (10.8.0.10)  ~140ms (via VPN gateway)\n    \u251c\u2500&gt; worker-1 (10.8.0.13)  ~144ms (via VPN gateway)\n    \u2514\u2500&gt; worker-3 (10.8.0.15)  ~140ms (via VPN gateway)\n\nmaster-1 (10.8.0.10) \u2192 master-2 (10.8.0.11)  ~7ms (direct tunnel)\nmaster-1 (10.8.0.10) \u2192 worker-1 (10.8.0.13)  ~7ms (direct tunnel)\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#dns-resolution-flow","title":"DNS Resolution Flow","text":"<pre><code>Client Request: https://argocd.kube.chalkan3.com.br\n\n1. DNS Lookup\n   \u2514\u2500&gt; DigitalOcean DNS Server\n       \u2514\u2500&gt; Returns: 10.8.0.13 (VPN IP)\n\n2. Route via VPN\n   Your Client (10.8.0.2)\n       \u2514\u2500&gt; VPN Server (10.8.0.1)\n           \u2514\u2500&gt; worker-1 (10.8.0.13)\n\n3. Nginx Ingress Controller (worker-1:443)\n       \u2514\u2500&gt; Checks Host header\n           \u2514\u2500&gt; Matches: argocd.kube.chalkan3.com.br\n\n4. Forward to ClusterIP Service\n       \u2514\u2500&gt; argocd-server.argocd.svc.cluster.local:443\n\n5. Load balance to Pod\n       \u2514\u2500&gt; ArgoCD Server Pod :8080\n</code></pre>"},{"location":"NETWORK_DIAGRAM/#port-reference","title":"Port Reference","text":"Node Type Service Port Protocol Access Master Kubernetes API 6443 HTTPS VPN only Master etcd client 2379 TCP Internal only Master etcd peer 2380 TCP Internal only Master Kubelet 10250 HTTPS Internal only Worker Nginx Ingress 80 HTTP VPN only Worker Nginx Ingress 443 HTTPS VPN only Worker Kubelet 10250 HTTPS Internal only All WireGuard 51820 UDP Public All Calico BGP 179 TCP Internal only"},{"location":"QUICK_START/","title":"Quick Start Guide","text":""},{"location":"QUICK_START/#prerequisites","title":"Prerequisites","text":"<ul> <li>\u2705 WireGuard VPN connected</li> <li>\u2705 kubectl installed</li> <li>\u2705 <code>~/.kube/config</code> configured</li> </ul>"},{"location":"QUICK_START/#verify-cluster-access","title":"Verify Cluster Access","text":"<pre><code># Check VPN connectivity\nping 10.8.0.10\n\n# Verify kubectl access\nkubectl get nodes\n\n# Should show 6 nodes (3 masters + 3 workers) all Ready\n</code></pre>"},{"location":"QUICK_START/#common-tasks","title":"Common Tasks","text":""},{"location":"QUICK_START/#1-deploy-an-application-to-tools-workers","title":"1. Deploy an Application to Tools Workers","text":"<pre><code># Create deployment\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      nodeSelector:\n        workload: tools\n      tolerations:\n      - key: workload\n        operator: Equal\n        value: tools\n        effect: NoSchedule\n      containers:\n      - name: my-app\n        image: nginx:latest\n        ports:\n        - containerPort: 80\nEOF\n\n# Check deployment\nkubectl get pods -o wide\n</code></pre>"},{"location":"QUICK_START/#2-expose-service-via-ingress","title":"2. Expose Service via Ingress","text":"<pre><code># Create service\nkubectl expose deployment my-app --port=80 --type=ClusterIP\n\n# Create ingress\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-app-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: myapp.kube.chalkan3.com.br\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-app\n            port:\n              number: 80\nEOF\n\n# Add DNS record (replace with actual IP of a worker)\ndoctl compute domain records create chalkan3.com.br \\\n  --record-type A \\\n  --record-name myapp.kube \\\n  --record-data 10.8.0.13 \\\n  --record-ttl 300\n\n# Test access (wait ~30s for DNS propagation)\ncurl http://myapp.kube.chalkan3.com.br\n</code></pre>"},{"location":"QUICK_START/#3-check-application-logs","title":"3. Check Application Logs","text":"<pre><code># Get pod name\nkubectl get pods\n\n# Follow logs\nkubectl logs -f &lt;pod-name&gt;\n\n# View last 100 lines\nkubectl logs &lt;pod-name&gt; --tail=100\n</code></pre>"},{"location":"QUICK_START/#4-execute-commands-in-pod","title":"4. Execute Commands in Pod","text":"<pre><code># Get shell in pod\nkubectl exec -it &lt;pod-name&gt; -- /bin/bash\n\n# Run single command\nkubectl exec &lt;pod-name&gt; -- ls -la /app\n</code></pre>"},{"location":"QUICK_START/#5-scale-application","title":"5. Scale Application","text":"<pre><code># Scale up to 3 replicas\nkubectl scale deployment my-app --replicas=3\n\n# Scale down to 1 replica\nkubectl scale deployment my-app --replicas=1\n</code></pre>"},{"location":"QUICK_START/#node-targeting","title":"Node Targeting","text":""},{"location":"QUICK_START/#deploy-to-tools-workers-worker-1-worker-2","title":"Deploy to Tools Workers (worker-1, worker-2)","text":"<pre><code>nodeSelector:\n  workload: tools\ntolerations:\n- key: workload\n  operator: Equal\n  value: tools\n  effect: NoSchedule\n</code></pre>"},{"location":"QUICK_START/#deploy-to-misc-worker-worker-3","title":"Deploy to Misc Worker (worker-3)","text":"<pre><code>nodeSelector:\n  workload: misc\ntolerations:\n- key: workload\n  operator: Equal\n  value: misc\n  effect: NoSchedule\n</code></pre>"},{"location":"QUICK_START/#access-services","title":"Access Services","text":""},{"location":"QUICK_START/#argocd","title":"ArgoCD","text":"<pre><code># Web UI\nopen https://argocd.kube.chalkan3.com.br\n\n# CLI login\nargocd login argocd.kube.chalkan3.com.br \\\n  --username admin \\\n  --password w-13KcdiqsQwruLs \\\n  --insecure\n</code></pre>"},{"location":"QUICK_START/#kubernetes-dashboard-if-installed","title":"Kubernetes Dashboard (if installed)","text":"<pre><code>kubectl proxy\nopen http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\n</code></pre>"},{"location":"QUICK_START/#troubleshooting-quick-tips","title":"Troubleshooting Quick Tips","text":"<pre><code># Node not ready?\nkubectl describe node &lt;node-name&gt;\n\n# Pod not starting?\nkubectl describe pod &lt;pod-name&gt;\nkubectl logs &lt;pod-name&gt;\n\n# Ingress not working?\nkubectl get ingress\nkubectl describe ingress &lt;ingress-name&gt;\n\n# Check events\nkubectl get events --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"QUICK_START/#ssh-to-nodes","title":"SSH to Nodes","text":"<pre><code># Masters\nssh-k8s-master-1  # or: ssh -i ~/.ssh/kubernetes-clusters/production.pem root@10.8.0.10\nssh-k8s-master-2\nssh-k8s-master-3\n\n# Workers\nssh-k8s-worker-1\nssh-k8s-worker-2\nssh-k8s-worker-3\n</code></pre>"},{"location":"QUICK_START/#important-urls","title":"Important URLs","text":"<ul> <li>Kubernetes API: https://api.chalkan3.com.br:6443</li> <li>ArgoCD: https://argocd.kube.chalkan3.com.br</li> <li>Documentation: <code>~/.projects/do-droplet-create/docs/</code></li> </ul>"},{"location":"QUICK_START/#get-more-help","title":"Get More Help","text":"<pre><code># Full documentation\ncat ~/.projects/do-droplet-create/docs/README.md\n\n# Deployment examples\nls ~/.projects/do-droplet-create/docs/examples/\n\n# Cluster info\nkubectl cluster-info\n</code></pre>"},{"location":"faq/","title":"\ud83e\udda5 FAQ","text":"<p>Frequently Asked Questions. Slowly answered!</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-sloth-kubernetes","title":"What is Sloth Kubernetes?","text":"<p>Sloth Kubernetes is a single-binary CLI tool that deploys production-ready Kubernetes clusters across multiple cloud providers (DigitalOcean and Linode) with zero external dependencies. No Pulumi CLI, no Terraform, no kubectl required for deployment! \ud83e\udda5</p>"},{"location":"faq/#why-sloth","title":"Why \"Sloth\"?","text":"<p>Because we believe in doing things slowly and correctly! Like a sloth, we take our time to ensure your cluster is deployed properly, securely, and reliably. Good clusters are deployed slowly and surely! \ud83e\udda5</p>"},{"location":"faq/#is-it-really-free-of-external-dependencies","title":"Is it really free of external dependencies?","text":"<p>Yes! Unlike other tools that require: - Pulumi CLI - Terraform - kubectl - Multiple provider CLIs</p> <p>Sloth Kubernetes embeds everything in one binary using the Pulumi Automation API. Just download and run! \ud83e\udda5</p>"},{"location":"faq/#what-cloud-providers-are-supported","title":"What cloud providers are supported?","text":"<p>Currently: - \u2705 DigitalOcean (Droplets, VPC, DNS, Load Balancers) - \u2705 Linode (Instances, VPC, DNS, NodeBalancers)</p> <p>Coming soon: - \ud83d\udd1c AWS - \ud83d\udd1c Azure - \ud83d\udd1c GCP - \ud83d\udd1c Hetzner</p>"},{"location":"faq/#can-i-use-just-one-cloud-provider","title":"Can I use just one cloud provider?","text":"<p>Absolutely! While Sloth Kubernetes excels at multi-cloud deployments, you can use a single provider if you prefer. Just enable one provider in your config:</p> <pre><code>spec:\n  providers:\n    digitalocean:\n      enabled: true\n    linode:\n      enabled: false  # \ud83e\udda5 Single cloud is fine!\n</code></pre>"},{"location":"faq/#technical-questions","title":"Technical Questions","text":""},{"location":"faq/#does-sloth-kubernetes-require-pulumi-cli","title":"Does Sloth Kubernetes require Pulumi CLI?","text":"<p>No! This is a common question. Sloth Kubernetes uses the Pulumi Automation API which is embedded directly in the binary. You never need to install the Pulumi CLI separately. \ud83e\udda5</p>"},{"location":"faq/#where-is-cluster-state-stored","title":"Where is cluster state stored?","text":"<p>By default, state is stored locally in <code>~/.sloth/stacks/</code>. Each cluster has its own state directory:</p> <pre><code>~/.sloth/\n\u2514\u2500\u2500 stacks/\n    \u2514\u2500\u2500 my-cluster/\n        \u2514\u2500\u2500 .pulumi/\n            \u2514\u2500\u2500 stacks/\n                \u2514\u2500\u2500 my-cluster.json  # \ud83e\udda5 Your state\n</code></pre> <p>You can also use remote backends like S3, Azure Blob, or GCS for team collaboration.</p>"},{"location":"faq/#what-kubernetes-distribution-is-used","title":"What Kubernetes distribution is used?","text":"<p>RKE2 (Rancher Kubernetes Engine 2) by default. RKE2 is: - Security-focused - CIS benchmark compliant - Highly available - Production-ready - Actively maintained by SUSE/Rancher \ud83e\udda5</p>"},{"location":"faq/#can-i-use-a-different-kubernetes-distribution","title":"Can I use a different Kubernetes distribution?","text":"<p>Currently only RKE2 is supported. We chose RKE2 for its security features and CIS compliance. Other distributions may be added in the future based on community demand! \ud83e\udda5</p>"},{"location":"faq/#how-does-the-vpn-mesh-work","title":"How does the VPN mesh work?","text":"<p>Sloth Kubernetes automatically deploys a WireGuard VPN mesh:</p> <ol> <li>Creates a VPN server node</li> <li>Generates encryption keys for each node</li> <li>Configures WireGuard on all nodes</li> <li>Sets up routing between VPCs</li> <li>All nodes communicate over encrypted tunnels \ud83d\udd10</li> </ol> <p>The VPN allows nodes across different clouds to communicate securely as if they were on the same network!</p>"},{"location":"faq/#what-ports-need-to-be-open","title":"What ports need to be open?","text":"<p>Minimal ports:</p> Port Protocol Purpose 22 TCP SSH (from bastion only) 51820 UDP WireGuard VPN 6443 TCP Kubernetes API (via VPN) 9345 TCP RKE2 supervisor API (internal) <p>All other communication happens over the encrypted VPN mesh! \ud83e\udda5</p>"},{"location":"faq/#how-long-does-deployment-take","title":"How long does deployment take?","text":"<p>Typical times:</p> Cluster Size Time Details Simple (1 node) 3-5 min Single master+worker Small (3 nodes) 5-8 min 1 master, 2 workers HA (5+ nodes) 8-12 min 3 masters, 2+ workers Large (10+ nodes) 12-20 min Multi-cloud HA <p>Remember, we're sloths - we take our time! \ud83e\udda5</p>"},{"location":"faq/#cost-questions","title":"Cost Questions","text":""},{"location":"faq/#how-much-does-it-cost","title":"How much does it cost?","text":"<p>Sloth Kubernetes itself is free and open source! You only pay for:</p> <ol> <li>Cloud provider resources (nodes, VPCs, load balancers)</li> <li>Bandwidth (typically included in node pricing)</li> </ol> <p>Example costs:</p> Cluster Type Monthly Cost Details Dev $15-30 1-3 small nodes Staging $50-100 3-5 medium nodes Production $200-500 5-10 nodes, HA <p>Actual costs vary by provider and region. Check our examples for detailed breakdowns! \ud83e\udda5</p>"},{"location":"faq/#which-provider-is-cheaper","title":"Which provider is cheaper?","text":"<p>Generally: - Linode tends to be slightly cheaper for compute - DigitalOcean has simpler, more predictable pricing - Both offer free VPCs and bandwidth allowances</p> <p>Our recommendation: Use both! Multi-cloud diversity is worth the tiny price difference. \ud83e\udda5</p>"},{"location":"faq/#are-there-any-hidden-costs","title":"Are there any hidden costs?","text":"<p>No hidden costs! Watch out for: - \u2705 Bandwidth overage (rare, most providers include 1-5TB free) - \u2705 Load balancers ($10-15/month if you use them) - \u2705 DNS hosting (usually $1-2/month or free) - \u2705 Snapshots/backups (optional, $0.05/GB/month)</p>"},{"location":"faq/#can-i-save-money","title":"Can I save money?","text":"<p>Yes! Tips: 1. Use smaller node sizes for non-production 2. Share dev/staging clusters across teams 3. Use spot/preemptible instances (coming soon) 4. Enable cluster autoscaling (coming soon) 5. Destroy non-production clusters when not in use \ud83e\udda5</p>"},{"location":"faq/#security-questions","title":"Security Questions","text":""},{"location":"faq/#is-it-secure","title":"Is it secure?","text":"<p>Yes! Security features include: - \u2705 WireGuard VPN mesh (encrypted node communication) - \u2705 RKE2 with CIS benchmarks - \u2705 Secrets encryption at rest - \u2705 Private VPCs (nodes not directly exposed) - \u2705 Bastion host for access control - \u2705 Automatic firewall rules - \u2705 Pod security policies \ud83e\udda5</p>"},{"location":"faq/#should-i-use-this-in-production","title":"Should I use this in production?","text":"<p>Yes! Sloth Kubernetes is designed for production use. We recommend: - Use HA configuration (3+ masters) - Enable secrets encryption - Use bastion host - Apply CIS profiles - Enable monitoring - Regular backups \ud83e\udda5</p>"},{"location":"faq/#how-do-i-rotate-credentials","title":"How do I rotate credentials?","text":"<pre><code># Update API tokens\nexport DIGITALOCEAN_TOKEN=\"new_token\"\nexport LINODE_TOKEN=\"new_token\"\n\n# Re-deploy (won't recreate nodes)\nsloth-kubernetes deploy --config cluster.yaml  # \ud83e\udda5\n\n# Rotate SSH keys\nsloth-kubernetes nodes rotate-keys --pool all\n</code></pre>"},{"location":"faq/#what-about-compliance-hipaa-pci-etc","title":"What about compliance (HIPAA, PCI, etc.)?","text":"<p>RKE2 with CIS profiles provides a strong foundation for compliance. Additional requirements: - Enable secrets encryption \u2705 - Enable audit logging \u2705 - Use private networking only \u2705 - Implement network policies \u2705 - Regular backups and retention \u2705</p> <p>See our Compliance Example \ud83e\udda5</p>"},{"location":"faq/#operational-questions","title":"Operational Questions","text":""},{"location":"faq/#how-do-i-add-more-nodes","title":"How do I add more nodes?","text":"<pre><code># Edit config to increase count\nnodePools:\n  - name: workers\n    count: 5  # \ud83e\udda5 Was 3, now 5\n\n# Deploy (only adds new nodes)\nsloth-kubernetes deploy --config cluster.yaml\n</code></pre> <p>Or use the nodes command:</p> <pre><code>sloth-kubernetes nodes add --pool workers --count 2  # \ud83e\udda5\n</code></pre>"},{"location":"faq/#how-do-i-upgrade-kubernetes","title":"How do I upgrade Kubernetes?","text":"<pre><code># Update version in config\nkubernetes:\n  version: v1.29.0+rke2r1  # \ud83e\udda5 New version\n\n# Deploy (rolling upgrade)\nsloth-kubernetes deploy --config cluster.yaml\n</code></pre> <p>Sloth Kubernetes performs rolling upgrades automatically - no downtime! \ud83e\udda5</p>"},{"location":"faq/#how-do-i-backup-my-cluster","title":"How do I backup my cluster?","text":"<p>RKE2 includes automatic etcd snapshots:</p> <pre><code>kubernetes:\n  rke2:\n    snapshotScheduleCron: \"0 */6 * * *\"  # \ud83e\udda5 Every 6 hours\n    snapshotRetention: 30  # Keep 30 snapshots\n</code></pre> <p>Backups stored on master nodes at <code>/var/lib/rancher/rke2/server/db/snapshots/</code></p>"},{"location":"faq/#how-do-i-restore-from-backup","title":"How do I restore from backup?","text":"<pre><code># SSH to first master\nssh -J bastion-ip master-1\n\n# List snapshots\nls /var/lib/rancher/rke2/server/db/snapshots/\n\n# Restore \ud83e\udda5\nrke2 server --cluster-reset --cluster-reset-restore-path=/var/lib/rancher/rke2/server/db/snapshots/snapshot-name\n</code></pre>"},{"location":"faq/#can-i-use-kubectl","title":"Can I use kubectl?","text":"<p>Yes! After deployment:</p> <pre><code># Get kubeconfig\nsloth-kubernetes kubeconfig &gt; ~/.kube/config\n\n# Use kubectl normally \ud83e\udda5\nkubectl get nodes\nkubectl get pods -A\nkubectl apply -f manifest.yaml\n</code></pre>"},{"location":"faq/#how-do-i-destroy-a-cluster","title":"How do I destroy a cluster?","text":"<pre><code># Destroy everything\nsloth-kubernetes destroy --config cluster.yaml  # \ud83e\udda5\n\n# This removes:\n# - All nodes\n# - VPCs\n# - VPN server\n# - DNS records\n# - Load balancers\n</code></pre> <p>Warning: This is permanent! Make sure you've backed up any data first! \ud83e\udda5</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#deployment-is-stuck","title":"Deployment is stuck","text":"<p>Check the logs:</p> <pre><code># Enable debug mode\nsloth-kubernetes deploy --config cluster.yaml --debug  # \ud83e\udda5\n\n# Common issues:\n# - API rate limits (wait a few minutes)\n# - Network connectivity\n# - Incorrect API tokens\n# - Region not available\n</code></pre>"},{"location":"faq/#nodes-not-joining-cluster","title":"Nodes not joining cluster","text":"<p>Verify:</p> <pre><code># Check VPN connectivity\nsloth-kubernetes vpn status  # \ud83e\udda5\n\n# SSH to node and check RKE2\nssh -J bastion-ip node-ip\nsystemctl status rke2-server  # or rke2-agent\njournalctl -u rke2-server -f\n</code></pre>"},{"location":"faq/#cant-connect-to-cluster","title":"Can't connect to cluster","text":"<pre><code># Regenerate kubeconfig\nsloth-kubernetes kubeconfig &gt; ~/.kube/config  # \ud83e\udda5\n\n# Verify API server is running\nssh -J bastion-ip master-1\nsystemctl status rke2-server\n</code></pre>"},{"location":"faq/#need-more-help","title":"Need more help?","text":"<ul> <li>\ud83d\udcd6 Troubleshooting Guide</li> <li>\ud83d\udcac Community Slack</li> <li>\ud83d\udc1b GitHub Issues</li> <li>\ud83d\udce7 Email Support</li> </ul>"},{"location":"faq/#contributing","title":"Contributing","text":""},{"location":"faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>We love contributions! \ud83e\udda5</p> <ul> <li>\ud83d\udc1b Report bugs</li> <li>\ud83d\udca1 Suggest features</li> <li>\ud83d\udcdd Improve docs</li> <li>\ud83d\udd27 Submit PRs</li> <li>\ud83c\udf1f Star the repo</li> </ul> <p>See our Contributing Guide</p>"},{"location":"faq/#can-i-add-a-new-cloud-provider","title":"Can I add a new cloud provider?","text":"<p>Yes! We welcome provider contributions. See Provider Development Guide \ud83e\udda5</p>"},{"location":"faq/#how-do-i-request-a-feature","title":"How do I request a feature?","text":"<p>Open an issue with: - Feature description - Use case - Example configuration - Why it's important</p> <p>We prioritize features by community demand! \ud83e\udda5</p>"},{"location":"faq/#philosophy","title":"Philosophy","text":""},{"location":"faq/#why-build-this","title":"Why build this?","text":"<p>Existing tools are complex, require many dependencies, and have steep learning curves. We wanted something simple: - One binary - One config file - Works out of the box \ud83e\udda5</p>"},{"location":"faq/#whats-next-for-sloth-kubernetes","title":"What's next for Sloth Kubernetes?","text":"<p>Roadmap: - \ud83d\udd1c More cloud providers (AWS, Azure, GCP) - \ud83d\udd1c Cluster autoscaling - \ud83d\udd1c Cost optimization tools - \ud83d\udd1c Multi-region support - \ud83d\udd1c Disaster recovery features - \ud83d\udd1c Web UI for management</p> <p>Follow our Roadmap \ud83e\udda5</p> <p>Ancient Sloth Proverb \ud83e\udda5</p> <p>\"Questions are the path to knowledge. Ask slowly, learn surely!\"</p> <p>Still have questions? Join our community Slack - we're always happy to help! \ud83e\udda5</p>"},{"location":"advanced/architecture/","title":"\ud83e\udda5 Architecture","text":"<p>Deep dive into how Sloth Kubernetes works under the hood. For the curious sloths!</p>"},{"location":"advanced/architecture/#system-overview","title":"System Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  \ud83e\udda5 Sloth Kubernetes CLI                     \u2502\n\u2502                    (Single Binary)                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Config Parser  \u2502  \u2502 Orchestrator \u2502  \u2502 State Manager  \u2502  \u2502\n\u2502  \u2502   (YAML)   \ud83e\udda5  \u2502\u2192 \u2502   (Pulumi)\ud83e\udda5 \u2502\u2192 \u2502   (Local)  \ud83e\udda5  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502           \u2502                  \u2502                   \u2502          \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                              \u2193                               \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502              \u2502   Pulumi Automation API      \u2502               \u2502\n\u2502              \u2502   (Embedded, No CLI)    \ud83e\udda5   \u2502               \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                              \u2193                               \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502         \u2193                                          \u2193         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Cloud APIs  \u2502                          \u2502   SSH/RKE2  \u2502   \u2502\n\u2502  \u2502  (DO/Linode)\u2502                          \u2502  Installer  \u2502   \u2502\n\u2502  \u2502     \ud83e\udda5      \u2502                          \u2502     \ud83e\udda5      \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2193                                \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Cloud Resources       \u2502      \u2502  Kubernetes Cluster  \u2502\n    \u2502  \u2022 VPCs                \u2502      \u2502  \u2022 RKE2 Installed    \u2502\n    \u2502  \u2022 Droplets/Instances  \u2502      \u2502  \u2022 WireGuard VPN     \u2502\n    \u2502  \u2022 DNS Records     \ud83e\udda5  \u2502      \u2502  \u2022 Encrypted     \ud83e\udda5  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"advanced/architecture/#core-components","title":"Core Components","text":""},{"location":"advanced/architecture/#1-configuration-parser","title":"1. Configuration Parser","text":"<p>Location: <code>pkg/config/</code></p> <p>Parses YAML config files into Go structs:</p> <pre><code>// Main config structure\ntype ClusterConfig struct {\n    APIVersion string                  `yaml:\"apiVersion\"`\n    Kind       string                  `yaml:\"kind\"`\n    Metadata   ClusterMetadata         `yaml:\"metadata\"`\n    Spec       ClusterSpec             `yaml:\"spec\"`\n}\n\n// Providers config\ntype ProvidersConfig struct {\n    DigitalOcean *DigitalOceanProvider `yaml:\"digitalocean\"`\n    Linode       *LinodeProvider       `yaml:\"linode\"`\n}\n\n// Node pool config\ntype NodePool struct {\n    Name     string            `yaml:\"name\"`\n    Provider string            `yaml:\"provider\"`\n    Count    int               `yaml:\"count\"`\n    Roles    []string          `yaml:\"roles\"`\n    Size     string            `yaml:\"size\"`\n    Labels   map[string]string `yaml:\"labels\"`\n    Taints   []Taint           `yaml:\"taints\"`\n}\n</code></pre> <p>Validation:</p> <pre><code>// Validates configuration\nfunc (c *ClusterConfig) Validate() error {\n    // Check providers\n    if !c.Spec.Providers.DigitalOcean.Enabled &amp;&amp;\n       !c.Spec.Providers.Linode.Enabled {\n        return errors.New(\"at least one provider must be enabled\")\n    }\n\n    // Validate node pools\n    masterCount := 0\n    for _, pool := range c.Spec.NodePools {\n        if contains(pool.Roles, \"master\") {\n            masterCount += pool.Count\n        }\n    }\n\n    // \ud83e\udda5 Odd number of masters for etcd quorum\n    if masterCount &gt; 1 &amp;&amp; masterCount%2 == 0 {\n        return errors.New(\"master count must be odd for HA\")\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"advanced/architecture/#2-orchestrator","title":"2. Orchestrator","text":"<p>Location: <code>internal/orchestrator/</code></p> <p>Coordinates the deployment process:</p> <pre><code>type ClusterOrchestrator struct {\n    config        *config.ClusterConfig\n    pulumiStack   *auto.Stack\n    components    []Component\n}\n\n// Main deployment flow\nfunc (o *ClusterOrchestrator) Deploy(ctx context.Context) error {\n    // 1. Initialize Pulumi stack \ud83e\udda5\n    if err := o.initStack(ctx); err != nil {\n        return err\n    }\n\n    // 2. Create cloud resources (VPCs, nodes)\n    if err := o.provisionInfrastructure(ctx); err != nil {\n        return err\n    }\n\n    // 3. Setup WireGuard VPN\n    if o.config.Spec.Network.WireGuard.Create {\n        if err := o.setupVPN(ctx); err != nil {\n            return err\n        }\n    }\n\n    // 4. Install RKE2 on nodes\n    if err := o.installKubernetes(ctx); err != nil {\n        return err\n    }\n\n    // 5. Configure cluster\n    if err := o.configureCluster(ctx); err != nil {\n        return err\n    }\n\n    // 6. Bootstrap addons (GitOps, monitoring, etc)\n    if err := o.bootstrapAddons(ctx); err != nil {\n        return err\n    }\n\n    return nil\n}\n</code></pre> <p>Component Architecture:</p> <pre><code>// All infrastructure components implement this interface\ntype Component interface {\n    Create(ctx context.Context) error\n    Update(ctx context.Context) error\n    Delete(ctx context.Context) error\n    Status(ctx context.Context) (ComponentStatus, error)\n}\n\n// Components\nvar components = []Component{\n    &amp;VPCComponent{},           // \ud83e\udda5 Create VPCs\n    &amp;BastionComponent{},       // \ud83e\udda5 Create bastion host\n    &amp;VPNComponent{},           // \ud83e\udda5 Deploy WireGuard\n    &amp;NodeProvisioningComponent{}, // \ud83e\udda5 Provision nodes\n    &amp;RKE2InstallerComponent{}, // \ud83e\udda5 Install Kubernetes\n    &amp;DNSComponent{},           // \ud83e\udda5 Configure DNS\n    &amp;FirewallComponent{},      // \ud83e\udda5 Setup firewall rules\n}\n</code></pre>"},{"location":"advanced/architecture/#3-state-management","title":"3. State Management","text":"<p>Location: <code>internal/orchestrator/state_manager.go</code></p> <p>Uses Pulumi for infrastructure state:</p> <pre><code>type StateManager struct {\n    stackName   string\n    projectName string\n    stateDir    string\n}\n\n// Initialize Pulumi stack (no CLI required!)\nfunc (sm *StateManager) InitStack(ctx context.Context) (*auto.Stack, error) {\n    // Create local backend (file-based state)\n    backend := fmt.Sprintf(\"file://%s\", sm.stateDir)\n\n    // Create stack using Pulumi Automation API \ud83e\udda5\n    stack, err := auto.UpsertStackLocalSource(ctx, sm.stackName,\n        sm.projectName, backend)\n    if err != nil {\n        return nil, err\n    }\n\n    return stack, nil\n}\n\n// Get current state\nfunc (sm *StateManager) GetState(ctx context.Context) (*StateSnapshot, error) {\n    export, err := sm.stack.Export(ctx)\n    if err != nil {\n        return nil, err\n    }\n\n    // Parse state JSON\n    var snapshot StateSnapshot\n    if err := json.Unmarshal(export.Deployment, &amp;snapshot); err != nil {\n        return nil, err\n    }\n\n    return &amp;snapshot, nil\n}\n</code></pre> <p>State Directory Structure:</p> <pre><code>~/.sloth/\n\u251c\u2500\u2500 stacks/\n\u2502   \u251c\u2500\u2500 my-cluster/\n\u2502   \u2502   \u251c\u2500\u2500 .pulumi/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 stacks/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 my-cluster.json  # \ud83e\udda5 Stack state\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 backups/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 *.json.bak       # \ud83e\udda5 Automatic backups\n\u2502   \u2502   \u2514\u2500\u2500 Pulumi.yaml\n\u2502   \u2514\u2500\u2500 staging-cluster/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 credentials.json  # \ud83e\udda5 Encrypted API tokens (optional)\n</code></pre>"},{"location":"advanced/architecture/#4-cloud-providers","title":"4. Cloud Providers","text":""},{"location":"advanced/architecture/#digitalocean-integration","title":"DigitalOcean Integration","text":"<p>Location: <code>pkg/providers/digitalocean/</code></p> <pre><code>type DigitalOceanProvider struct {\n    client *godo.Client\n    config *config.DigitalOceanProvider\n}\n\n// Create VPC\nfunc (p *DigitalOceanProvider) CreateVPC(ctx *pulumi.Context) error {\n    vpc, err := digitalocean.NewVpc(ctx, \"vpc\", &amp;digitalocean.VpcArgs{\n        Name:   pulumi.String(p.config.VPC.Name),\n        Region: pulumi.String(p.config.Region),\n        IpRange: pulumi.String(p.config.VPC.CIDR),\n    })\n    // ... \ud83e\udda5\n}\n\n// Create Droplet\nfunc (p *DigitalOceanProvider) CreateDroplet(ctx *pulumi.Context,\n    pool *config.NodePool) error {\n\n    droplet, err := digitalocean.NewDroplet(ctx, pool.Name,\n        &amp;digitalocean.DropletArgs{\n            Name:   pulumi.String(pool.Name),\n            Size:   pulumi.String(pool.Size),\n            Image:  pulumi.String(\"ubuntu-22-04-x64\"),\n            Region: pulumi.String(p.config.Region),\n            VpcUuid: vpc.ID(), // \ud83e\udda5 Attach to VPC\n            SshKeys: pulumi.StringArray{sshKeyID},\n        })\n    // ... \ud83e\udda5\n}\n</code></pre>"},{"location":"advanced/architecture/#linode-integration","title":"Linode Integration","text":"<p>Location: <code>pkg/providers/linode/</code></p> <pre><code>type LinodeProvider struct {\n    client *linodego.Client\n    config *config.LinodeProvider\n}\n\n// Create Instance\nfunc (p *LinodeProvider) CreateInstance(ctx *pulumi.Context,\n    pool *config.NodePool) error {\n\n    instance, err := linode.NewInstance(ctx, pool.Name,\n        &amp;linode.InstanceArgs{\n            Label:  pulumi.String(pool.Name),\n            Type:   pulumi.String(pool.Size),\n            Image:  pulumi.String(\"linode/ubuntu22.04\"),\n            Region: pulumi.String(p.config.Region),\n            // ... \ud83e\udda5\n        })\n    // ...\n}\n</code></pre>"},{"location":"advanced/architecture/#5-wireguard-vpn","title":"5. WireGuard VPN","text":"<p>Location: <code>pkg/vpn/wireguard.go</code></p> <p>Automatic VPN mesh networking:</p> <pre><code>type WireGuardManager struct {\n    serverNode  *Node\n    clientNodes []*Node\n    config      *config.WireGuardConfig\n}\n\n// Deploy VPN server\nfunc (wg *WireGuardManager) DeployServer(ctx context.Context) error {\n    // 1. Generate server keys \ud83e\udda5\n    privateKey, publicKey, err := wg.generateKeyPair()\n\n    // 2. Install WireGuard on server node\n    installScript := `\n        apt-get update\n        apt-get install -y wireguard\n\n        # Configure interface \ud83e\udda5\n        cat &gt; /etc/wireguard/wg0.conf &lt;&lt;EOF\n[Interface]\nPrivateKey = ` + privateKey + `\nAddress = 10.8.0.1/24\nListenPort = 51820\nPostUp = iptables -A FORWARD -i wg0 -j ACCEPT\nPostDown = iptables -D FORWARD -i wg0 -j ACCEPT\nEOF\n\n        # Start VPN \ud83e\udda5\n        systemctl enable wg-quick@wg0\n        systemctl start wg-quick@wg0\n    `\n\n    // 3. Execute via SSH\n    if err := wg.executeSSH(ctx, wg.serverNode, installScript); err != nil {\n        return err\n    }\n\n    // 4. Configure firewall\n    if err := wg.configureFirewall(ctx); err != nil {\n        return err\n    }\n\n    return nil\n}\n\n// Configure VPN client on each node\nfunc (wg *WireGuardManager) ConfigureClient(ctx context.Context,\n    node *Node) error {\n\n    // Generate client keys\n    privateKey, publicKey, _ := wg.generateKeyPair()\n\n    // Assign VPN IP\n    vpnIP := wg.getNextAvailableIP()\n\n    // Configure client\n    clientConfig := fmt.Sprintf(`\n[Interface]\nPrivateKey = %s\nAddress = %s/24\n\n[Peer]\nPublicKey = %s\nEndpoint = %s:51820\nAllowedIPs = 10.8.0.0/24, %s, %s\nPersistentKeepalive = 25\n`, privateKey, vpnIP, wg.serverPublicKey,\n   wg.serverNode.PublicIP, vpc1CIDR, vpc2CIDR)\n\n    // Install on node \ud83e\udda5\n    return wg.installClientConfig(ctx, node, clientConfig)\n}\n</code></pre> <p>VPN Mesh Topology:</p> <pre><code>                  \ud83e\udda5 VPN Server \ud83e\udda5\n                   (10.8.0.1)\n                  203.0.113.10\n                       \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502               \u2502               \u2502\n   DO Master 1     DO Master 2    Linode Master 1\n   (10.8.0.2)      (10.8.0.3)      (10.8.0.4)\n   10.10.1.5       10.10.1.6       10.11.1.5\n       \u2502               \u2502               \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n              All nodes communicate\n           via encrypted VPN tunnel \ud83d\udd10\n</code></pre>"},{"location":"advanced/architecture/#6-rke2-installer","title":"6. RKE2 Installer","text":"<p>Location: <code>pkg/kubernetes/rke2_installer.go</code></p> <p>Installs and configures RKE2:</p> <pre><code>type RKE2Installer struct {\n    config    *config.KubernetesConfig\n    nodes     []*Node\n    masterIPs []string\n}\n\n// Install on master nodes\nfunc (r *RKE2Installer) InstallMasters(ctx context.Context) error {\n    for i, master := range r.getMasterNodes() {\n        if i == 0 {\n            // First master initializes cluster \ud83e\udda5\n            err := r.installFirstMaster(ctx, master)\n        } else {\n            // Other masters join existing cluster\n            err := r.installAdditionalMaster(ctx, master)\n        }\n\n        if err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// Install first master\nfunc (r *RKE2Installer) installFirstMaster(ctx context.Context,\n    node *Node) error {\n\n    config := fmt.Sprintf(`\n# RKE2 Server Config \ud83e\udda5\nwrite-kubeconfig-mode: \"0644\"\ntls-san:\n  - %s\n  - %s\ncluster-cidr: \"10.42.0.0/16\"\nservice-cidr: \"10.43.0.0/16\"\n`, node.PublicIP, node.PrivateIP)\n\n    // Add secrets encryption if enabled\n    if r.config.RKE2.SecretsEncryption {\n        config += `\nsecrets-encryption: true\n`\n    }\n\n    // Add CIS profile if configured\n    if len(r.config.RKE2.Profiles) &gt; 0 {\n        config += fmt.Sprintf(`\nprofile: %s\n`, r.config.RKE2.Profiles[0])\n    }\n\n    // Write config and install \ud83e\udda5\n    installScript := fmt.Sprintf(`\n        # Write config\n        mkdir -p /etc/rancher/rke2\n        cat &gt; /etc/rancher/rke2/config.yaml &lt;&lt;'EOF'\n%s\nEOF\n\n        # Install RKE2\n        curl -sfL https://get.rke2.io | INSTALL_RKE2_VERSION=%s sh -\n\n        # Enable and start \ud83e\udda5\n        systemctl enable rke2-server\n        systemctl start rke2-server\n\n        # Wait for startup\n        until systemctl is-active rke2-server; do\n            sleep 5\n        done\n\n        # Get join token for other nodes\n        cat /var/lib/rancher/rke2/server/node-token\n    `, config, r.config.Version)\n\n    output, err := r.executeSSH(ctx, node, installScript)\n    if err != nil {\n        return err\n    }\n\n    // Save join token \ud83e\udda5\n    r.joinToken = strings.TrimSpace(output)\n\n    return nil\n}\n\n// Install worker nodes\nfunc (r *RKE2Installer) InstallWorkers(ctx context.Context) error {\n    workerConfig := fmt.Sprintf(`\nserver: https://%s:9345\ntoken: %s\n`, r.masterIPs[0], r.joinToken)\n\n    installScript := fmt.Sprintf(`\n        mkdir -p /etc/rancher/rke2\n        cat &gt; /etc/rancher/rke2/config.yaml &lt;&lt;'EOF'\n%s\nEOF\n\n        curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE=agent \\\n            INSTALL_RKE2_VERSION=%s sh -\n\n        systemctl enable rke2-agent\n        systemctl start rke2-agent  # \ud83e\udda5\n    `, workerConfig, r.config.Version)\n\n    // Install on all workers in parallel\n    errChan := make(chan error, len(r.getWorkerNodes()))\n    for _, worker := range r.getWorkerNodes() {\n        go func(node *Node) {\n            errChan &lt;- r.executeSSH(ctx, node, installScript)\n        }(worker)\n    }\n\n    // Wait for all \ud83e\udda5\n    for range r.getWorkerNodes() {\n        if err := &lt;-errChan; err != nil {\n            return err\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"advanced/architecture/#7-dns-management","title":"7. DNS Management","text":"<p>Location: <code>pkg/dns/manager.go</code></p> <p>Automatic DNS record creation:</p> <pre><code>type DNSManager struct {\n    provider string\n    domain   string\n    records  []*config.DNSRecord\n}\n\n// Create DNS records for nodes\nfunc (d *DNSManager) CreateRecords(ctx *pulumi.Context,\n    nodes []*Node) error {\n\n    for _, node := range nodes {\n        // Create A record for each node \ud83e\udda5\n        _, err := digitalocean.NewDnsRecord(ctx,\n            fmt.Sprintf(\"%s-record\", node.Name),\n            &amp;digitalocean.DnsRecordArgs{\n                Domain: pulumi.String(d.domain),\n                Type:   pulumi.String(\"A\"),\n                Name:   pulumi.String(node.Name),\n                Value:  pulumi.String(node.PublicIP),\n                Ttl:    pulumi.Int(300),\n            })\n\n        if err != nil {\n            return err\n        }\n    }\n\n    // Create wildcard record for ingress \ud83e\udda5\n    if d.records.IngressWildcard {\n        ingressIP := d.getIngressIP(ctx)\n        _, err := digitalocean.NewDnsRecord(ctx, \"wildcard-ingress\",\n            &amp;digitalocean.DnsRecordArgs{\n                Domain: pulumi.String(d.domain),\n                Type:   pulumi.String(\"A\"),\n                Name:   pulumi.String(\"*\"),\n                Value:  pulumi.String(ingressIP),\n                Ttl:    pulumi.Int(300),\n            })\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"advanced/architecture/#deployment-flow","title":"Deployment Flow","text":"<p>Detailed step-by-step process:</p> <pre><code>1. Parse Configuration \ud83e\udda5\n   \u251c\u2500 Read YAML file\n   \u251c\u2500 Validate structure\n   \u251c\u2500 Expand environment variables\n   \u2514\u2500 Validate semantics\n\n2. Initialize Pulumi Stack \ud83e\udda5\n   \u251c\u2500 Create local backend\n   \u251c\u2500 Load or create stack\n   \u2514\u2500 Configure providers\n\n3. Create VPCs \ud83e\udda5\n   \u251c\u2500 DigitalOcean VPC (if enabled)\n   \u2514\u2500 Linode VPC (if enabled)\n\n4. Deploy Bastion (if enabled) \ud83e\udda5\n   \u251c\u2500 Create bastion host\n   \u251c\u2500 Configure SSH access\n   \u2514\u2500 Setup port forwarding\n\n5. Deploy WireGuard VPN (if enabled) \ud83e\udda5\n   \u251c\u2500 Provision VPN server\n   \u251c\u2500 Generate keys\n   \u251c\u2500 Configure firewall\n   \u2514\u2500 Start VPN service\n\n6. Provision Nodes \ud83e\udda5\n   \u251c\u2500 Create master nodes\n   \u251c\u2500 Create worker nodes\n   \u251c\u2500 Attach to VPCs\n   \u251c\u2500 Configure SSH keys\n   \u2514\u2500 Wait for nodes to be ready\n\n7. Configure VPN Clients \ud83e\udda5\n   \u251c\u2500 Generate client keys\n   \u251c\u2500 Assign VPN IPs\n   \u251c\u2500 Install WireGuard on nodes\n   \u2514\u2500 Connect to VPN mesh\n\n8. Install Kubernetes \ud83e\udda5\n   \u251c\u2500 Install first master\n   \u251c\u2500 Get join token\n   \u251c\u2500 Install additional masters\n   \u251c\u2500 Install workers\n   \u2514\u2500 Wait for cluster ready\n\n9. Configure DNS (if enabled) \ud83e\udda5\n   \u251c\u2500 Create node A records\n   \u2514\u2500 Create wildcard for ingress\n\n10. Bootstrap Addons \ud83e\udda5\n    \u251c\u2500 Install NGINX Ingress\n    \u251c\u2500 Install cert-manager\n    \u251c\u2500 Bootstrap ArgoCD (if enabled)\n    \u2514\u2500 Apply custom manifests\n\n11. Generate Kubeconfig \ud83e\udda5\n    \u251c\u2500 Fetch from master\n    \u251c\u2500 Update server address\n    \u2514\u2500 Save locally\n\n12. Deployment Complete! \ud83e\udda5\n    \u2514\u2500 Print summary and next steps\n</code></pre>"},{"location":"advanced/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"advanced/architecture/#secrets-encryption","title":"Secrets Encryption","text":"<p>RKE2 can encrypt secrets at rest:</p> <pre><code># Enabled in config\nkubernetes:\n  rke2:\n    secretsEncryption: true\n</code></pre> <p>What happens:</p> <ol> <li>RKE2 generates encryption key</li> <li>Stores key in <code>/var/lib/rancher/rke2/server/cred/encryption-config.json</code></li> <li>All Secrets encrypted before writing to etcd</li> <li>Transparent decryption on read</li> </ol>"},{"location":"advanced/architecture/#network-security","title":"Network Security","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Internet (Untrusted)                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u2193\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  Bastion Host (SSH)  \u2502  \ud83e\udda5 Only entry point\n         \u2502    203.0.113.5       \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u2193\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  WireGuard VPN       \u2502  \ud83d\udd10 Encrypted tunnel\n         \u2502  10.8.0.1 (Server)   \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2193                         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  VPC (DO)   \u2502           \u2502 VPC (Linode)\u2502\n\u2502 10.10.0.0/16\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 10.11.0.0/16\u2502  \ud83e\udda5 Private\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   VPN     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502                          \u2502\n    \u2193                          \u2193\nMaster/Worker              Master/Worker\n  Nodes                      Nodes\n</code></pre>"},{"location":"advanced/architecture/#firewall-rules","title":"Firewall Rules","text":"<p>Automatically configured:</p> <pre><code>// Inbound rules\nvar firewallRules = []FirewallRule{\n    // SSH from bastion only\n    {\n        Port:     22,\n        Protocol: \"tcp\",\n        Sources:  []string{bastionIP},\n    },\n    // WireGuard VPN\n    {\n        Port:     51820,\n        Protocol: \"udp\",\n        Sources:  []string{\"0.0.0.0/0\"},  // Public\n    },\n    // Kubernetes API (from VPN only)\n    {\n        Port:     6443,\n        Protocol: \"tcp\",\n        Sources:  []string{\"10.8.0.0/24\"},  // VPN subnet\n    },\n    // All traffic within VPC\n    {\n        Port:     \"all\",\n        Protocol: \"all\",\n        Sources:  []string{vpcCIDR},\n    },\n}\n</code></pre>"},{"location":"advanced/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"advanced/architecture/#parallel-operations","title":"Parallel Operations","text":"<p>Many operations run in parallel:</p> <pre><code>// Provision nodes in parallel \ud83e\udda5\nfunc (o *Orchestrator) provisionNodes(pools []*NodePool) error {\n    var wg sync.WaitGroup\n    errChan := make(chan error, len(pools))\n\n    for _, pool := range pools {\n        wg.Add(1)\n        go func(p *NodePool) {\n            defer wg.Done()\n            if err := o.createNodePool(p); err != nil {\n                errChan &lt;- err\n            }\n        }(pool)\n    }\n\n    wg.Wait()\n    close(errChan)\n\n    // Check for errors\n    for err := range errChan {\n        if err != nil {\n            return err\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"advanced/architecture/#resource-limits","title":"Resource Limits","text":"<p>Default limits (configurable):</p> <ul> <li>Max parallel node provisions: 10</li> <li>Max parallel RKE2 installs: 5</li> <li>SSH connection timeout: 5 minutes</li> <li>Total deployment timeout: 30 minutes</li> </ul>"},{"location":"advanced/architecture/#extensibility","title":"Extensibility","text":""},{"location":"advanced/architecture/#custom-components","title":"Custom Components","text":"<p>Add your own components:</p> <pre><code>// pkg/components/custom.go\ntype CustomComponent struct {\n    config *CustomConfig\n}\n\nfunc (c *CustomComponent) Create(ctx context.Context) error {\n    // Your custom logic \ud83e\udda5\n    return nil\n}\n\n// Register in orchestrator\norchestrator.RegisterComponent(&amp;CustomComponent{})\n</code></pre>"},{"location":"advanced/architecture/#hooks","title":"Hooks","text":"<p>Run custom code at specific points:</p> <pre><code>// Pre-deployment hook\norchestrator.OnPreDeploy(func(ctx context.Context) error {\n    log.Info(\"\ud83e\udda5 Running custom pre-deployment checks...\")\n    return validateCustomRequirements()\n})\n\n// Post-deployment hook\norchestrator.OnPostDeploy(func(ctx context.Context) error {\n    log.Info(\"\ud83e\udda5 Running custom post-deployment tasks...\")\n    return setupCustomMonitoring()\n})\n</code></pre>"},{"location":"advanced/architecture/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/architecture/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging:</p> <pre><code>sloth-kubernetes deploy --debug\n</code></pre> <p>Shows:</p> <ul> <li>Pulumi resource operations</li> <li>SSH commands executed</li> <li>API calls to cloud providers</li> <li>State changes</li> </ul>"},{"location":"advanced/architecture/#state-inspection","title":"State Inspection","text":"<p>View current state:</p> <pre><code># List all resources\nsloth-kubernetes stacks state list\n\n# Export state for debugging\nsloth-kubernetes stacks export &gt; state.json\n</code></pre>"},{"location":"advanced/architecture/#manual-recovery","title":"Manual Recovery","text":"<p>If deployment fails partway:</p> <pre><code># Check what was created\nsloth-kubernetes stacks state list\n\n# Remove specific failed resource\nsloth-kubernetes stacks state delete &lt;urn&gt;\n\n# Resume deployment\nsloth-kubernetes deploy --config cluster.yaml\n</code></pre> <p>Sloth Wisdom \ud83e\udda5</p> <p>\"Understanding the architecture makes you a better operator. Take time to learn!\"</p> <p>Want to contribute? Check out Contributing Guide \ud83e\udda5</p>"},{"location":"configuration/examples/","title":"\ud83e\udda5 Configuration Examples","text":"<p>Real-world cluster configurations for every scenario. Copy, paste, and customize at your own pace!</p>"},{"location":"configuration/examples/#simple-single-cloud-cluster","title":"Simple Single-Cloud Cluster","text":"<p>Perfect for development or small projects. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: simple-dev\n  labels:\n    environment: development\n\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}  # \ud83e\udda5 From environment\n      region: nyc3\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n\n  nodePools:\n    - name: all-in-one\n      provider: digitalocean\n      count: 1  # \ud83e\udda5 Single node for dev\n      roles: [master, worker]\n      size: s-2vcpu-4gb\n</code></pre> <p>What you get:</p> <ul> <li>1 node serving as both master and worker</li> <li>No VPN (single node doesn't need it)</li> <li>Perfect for testing</li> <li>Cost: ~$24/month</li> </ul>"},{"location":"configuration/examples/#production-ha-multi-cloud","title":"Production HA Multi-Cloud","text":"<p>High availability across multiple clouds. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: production-ha\n  labels:\n    environment: production\n    tier: critical\n\nspec:\n  providers:\n    # DigitalOcean for masters\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.10.0.0/16\n\n    # Linode for masters and workers\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}\n      region: us-east\n      vpc:\n        create: true\n        cidr: 10.11.0.0/16\n\n  # \ud83e\udda5 Secure VPN mesh\n  network:\n    wireguard:\n      create: true\n      meshNetworking: true\n      subnet: 10.8.0.0/24\n      port: 51820\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n    rke2:\n      secretsEncryption: true  # \ud83e\udda5 Encrypt at rest\n      snapshotScheduleCron: \"0 */6 * * *\"  # Backup every 6 hours\n      profiles:\n        - cis-1.6  # CIS security benchmark\n\n  nodePools:\n    # Masters across clouds for HA\n    - name: do-masters\n      provider: digitalocean\n      count: 1\n      roles: [master]\n      size: s-2vcpu-4gb\n      tags: [master, production]\n\n    - name: linode-masters\n      provider: linode\n      count: 2  # \ud83e\udda5 3 total masters (quorum)\n      roles: [master]\n      size: g6-standard-2\n      tags: [master, production]\n\n    # Workers for application workloads\n    - name: do-workers\n      provider: digitalocean\n      count: 2\n      roles: [worker]\n      size: s-4vcpu-8gb  # \ud83e\udda5 More resources for apps\n      tags: [worker, production]\n\n    - name: linode-workers\n      provider: linode\n      count: 2\n      roles: [worker]\n      size: g6-standard-4\n      tags: [worker, production]\n\n  # \ud83e\udda5 Bastion for secure access\n  security:\n    bastion:\n      enabled: true\n      provider: digitalocean\n      size: s-1vcpu-1gb\n      allowedIPs:\n        - \"203.0.113.0/24\"  # Your office IP range\n\n  # \ud83e\udda5 GitOps with ArgoCD\n  addons:\n    gitops:\n      enabled: true\n      repository: https://github.com/yourorg/k8s-gitops\n      branch: main\n</code></pre> <p>What you get:</p> <ul> <li>3 master nodes (1 DO + 2 Linode) for HA</li> <li>4 worker nodes across both clouds</li> <li>WireGuard VPN mesh</li> <li>Encrypted secrets</li> <li>CIS security benchmarks</li> <li>Automated backups every 6 hours</li> <li>Bastion host for secure access</li> <li>ArgoCD for GitOps</li> <li>Cost: ~$240/month</li> </ul>"},{"location":"configuration/examples/#cost-optimized-cluster","title":"Cost-Optimized Cluster","text":"<p>Maximum value for minimum spend. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: budget-friendly\n  labels:\n    environment: staging\n    cost-optimized: \"true\"\n\nspec:\n  providers:\n    # Linode (generally cheaper)\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}\n      region: us-east\n      vpc:\n        create: true\n        cidr: 10.20.0.0/16\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n\n  nodePools:\n    # Single master (not HA, but cheap!)\n    - name: master\n      provider: linode\n      count: 1\n      roles: [master]\n      size: g6-nanode-1  # \ud83e\udda5 Smallest size: $5/month\n      tags: [master, staging]\n\n    # 2 small workers\n    - name: workers\n      provider: linode\n      count: 2\n      roles: [worker]\n      size: g6-nanode-1  # \ud83e\udda5 Also $5/month each\n      tags: [worker, staging]\n</code></pre> <p>What you get:</p> <ul> <li>1 master + 2 workers</li> <li>Single cloud (no VPN overhead)</li> <li>Basic Kubernetes functionality</li> <li>Perfect for staging/testing</li> <li>Cost: ~$15/month</li> </ul>"},{"location":"configuration/examples/#gpu-workloads-cluster","title":"GPU Workloads Cluster","text":"<p>For ML/AI and GPU-intensive workloads. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: gpu-cluster\n  labels:\n    environment: ml-training\n    workload: gpu\n\nspec:\n  providers:\n    # DigitalOcean for control plane\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.30.0.0/16\n\n    # Linode for GPU nodes\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}\n      region: us-east\n      vpc:\n        create: true\n        cidr: 10.31.0.0/16\n\n  network:\n    wireguard:\n      create: true\n      meshNetworking: true\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n\n  nodePools:\n    # Control plane on DO\n    - name: masters\n      provider: digitalocean\n      count: 3\n      roles: [master]\n      size: s-2vcpu-4gb\n\n    # CPU workers for system services\n    - name: cpu-workers\n      provider: digitalocean\n      count: 2\n      roles: [worker]\n      size: s-4vcpu-8gb\n      labels:\n        node-type: cpu  # \ud83e\udda5 Label for scheduling\n\n    # GPU workers for ML workloads\n    - name: gpu-workers\n      provider: linode\n      count: 2\n      roles: [worker]\n      size: g1-gpu-rtx6000-1  # \ud83e\udda5 RTX 6000 GPU\n      labels:\n        node-type: gpu\n        nvidia.com/gpu: \"true\"\n      taints:\n        - key: nvidia.com/gpu\n          value: \"true\"\n          effect: NoSchedule  # \ud83e\udda5 Only GPU pods here\n</code></pre> <p>Example GPU pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-training\nspec:\n  nodeSelector:\n    node-type: gpu  # \ud83e\udda5 Schedule on GPU nodes\n  tolerations:\n    - key: nvidia.com/gpu\n      operator: Exists\n  containers:\n    - name: pytorch\n      image: pytorch/pytorch:latest\n      resources:\n        limits:\n          nvidia.com/gpu: 1  # \ud83e\udda5 Request GPU\n</code></pre>"},{"location":"configuration/examples/#edge-computing-cluster","title":"Edge Computing Cluster","text":"<p>Distributed edge locations. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: edge-distributed\n  labels:\n    environment: edge\n    topology: distributed\n\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      regions:  # \ud83e\udda5 Multiple regions!\n        - nyc3\n        - sfo3\n        - ams3\n\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}\n      regions:\n        - us-east\n        - us-west\n        - eu-central\n\n  network:\n    wireguard:\n      create: true\n      meshNetworking: true\n      subnet: 10.8.0.0/24\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n\n  nodePools:\n    # Masters in primary region\n    - name: central-masters\n      provider: digitalocean\n      region: nyc3\n      count: 3\n      roles: [master]\n      size: s-2vcpu-4gb\n\n    # Edge workers in NYC\n    - name: nyc-edge\n      provider: digitalocean\n      region: nyc3\n      count: 2\n      roles: [worker]\n      size: s-2vcpu-4gb\n      labels:\n        edge-location: nyc  # \ud83e\udda5 Location-aware scheduling\n\n    # Edge workers in SF\n    - name: sfo-edge\n      provider: digitalocean\n      region: sfo3\n      count: 2\n      roles: [worker]\n      size: s-2vcpu-4gb\n      labels:\n        edge-location: sfo\n\n    # Edge workers in Amsterdam\n    - name: ams-edge\n      provider: digitalocean\n      region: ams3\n      count: 2\n      roles: [worker]\n      size: s-2vcpu-4gb\n      labels:\n        edge-location: ams\n\n    # Edge workers in Asia\n    - name: asia-edge\n      provider: linode\n      region: ap-south\n      count: 2\n      roles: [worker]\n      size: g6-standard-2\n      labels:\n        edge-location: asia\n</code></pre> <p>Deploy geographically:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cdn-cache\nspec:\n  replicas: 8\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n            - weight: 100\n              podAffinityTerm:\n                labelSelector:\n                  matchExpressions:\n                    - key: app\n                      operator: In\n                      values: [cdn-cache]\n                topologyKey: edge-location  # \ud83e\udda5 Spread across locations\n</code></pre>"},{"location":"configuration/examples/#development-team-cluster","title":"Development Team Cluster","text":"<p>For collaborative development teams. \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: dev-team\n  labels:\n    environment: development\n    team: engineering\n\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.50.0.0/16\n\n  network:\n    wireguard:\n      create: true\n      meshNetworking: true\n      clients:  # \ud83e\udda5 VPN for developers\n        - name: alice-laptop\n          allowedIPs: [10.8.0.100/32]\n        - name: bob-laptop\n          allowedIPs: [10.8.0.101/32]\n        - name: charlie-laptop\n          allowedIPs: [10.8.0.102/32]\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n    rke2:\n      profiles:\n        - cis-1.6  # \ud83e\udda5 Security even in dev!\n\n  nodePools:\n    - name: masters\n      provider: digitalocean\n      count: 1  # Single master for dev\n      roles: [master]\n      size: s-2vcpu-4gb\n\n    - name: workers\n      provider: digitalocean\n      count: 3\n      roles: [worker]\n      size: s-4vcpu-8gb  # \ud83e\udda5 Enough for multiple apps\n      labels:\n        node-type: general\n\n  # \ud83e\udda5 Pre-install development tools\n  addons:\n    gitops:\n      enabled: true\n      repository: https://github.com/yourorg/dev-cluster-config\n      applications:\n        - name: dev-namespace-creator\n          path: namespaces/\n        - name: ingress-nginx\n          path: ingress/\n        - name: cert-manager\n          path: cert-manager/\n        - name: monitoring\n          path: monitoring/\n\n  # \ud83e\udda5 DNS for easy access\n  dns:\n    enabled: true\n    domain: dev.yourcompany.com\n    provider: digitalocean\n    records:\n      - name: \"*.dev\"\n        type: A\n        value: \"${INGRESS_IP}\"\n</code></pre> <p>Team members can:</p> <ul> <li>Connect via VPN to access internal services</li> <li>Deploy to their own namespaces</li> <li>Use <code>*.dev.yourcompany.com</code> domains</li> <li>Share the cluster without conflicts</li> </ul>"},{"location":"configuration/examples/#compliance-first-cluster","title":"Compliance-First Cluster","text":"<p>For regulated industries (healthcare, finance). \ud83e\udda5</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: compliance-cluster\n  labels:\n    environment: production\n    compliance: hipaa-pci\n\nspec:\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.100.0.0/16\n\n  network:\n    wireguard:\n      create: true\n      meshNetworking: true\n      # \ud83e\udda5 Strong encryption\n      allowedCipherSuites:\n        - TLS_AES_256_GCM_SHA384\n\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n    rke2:\n      secretsEncryption: true  # \ud83e\udda5 Required for compliance\n      snapshotScheduleCron: \"0 */4 * * *\"  # Backup every 4 hours\n      snapshotRetention: 72  # Keep 72 backups (2 weeks)\n      auditLogEnabled: true  # \ud83e\udda5 Audit all API calls\n      profiles:\n        - cis-1.6  # CIS benchmarks\n      podSecurityPolicy: restricted  # Strictest policy\n\n  nodePools:\n    - name: masters\n      provider: digitalocean\n      count: 3  # \ud83e\udda5 HA required\n      roles: [master]\n      size: s-4vcpu-8gb\n      encrypted: true  # Encrypted volumes\n      tags: [master, compliance]\n\n    - name: workers\n      provider: digitalocean\n      count: 4\n      roles: [worker]\n      size: s-8vcpu-16gb\n      encrypted: true  # \ud83e\udda5 All volumes encrypted\n      tags: [worker, compliance]\n\n  # \ud83e\udda5 Strict security controls\n  security:\n    bastion:\n      enabled: true\n      provider: digitalocean\n      size: s-1vcpu-1gb\n      allowedIPs:\n        - \"203.0.113.0/24\"  # Only from office\n      mfaRequired: true\n\n    networkPolicies:\n      enabled: true\n      defaultDeny: true  # \ud83e\udda5 Deny all, allow explicitly\n\n    podSecurityStandards:\n      enforce: restricted\n      audit: restricted\n      warn: restricted\n\n  # \ud83e\udda5 Monitoring and alerting\n  addons:\n    monitoring:\n      enabled: true\n      retentionDays: 90  # Keep logs for compliance\n      alerts:\n        - unauthorizedAccess\n        - configChanges\n        - podSecurityViolations\n</code></pre> <p>Compliance features:</p> <ul> <li>\u2705 Encrypted volumes</li> <li>\u2705 Encrypted secrets at rest</li> <li>\u2705 Audit logging enabled</li> <li>\u2705 CIS benchmarks enforced</li> <li>\u2705 Network policies (default deny)</li> <li>\u2705 Pod security standards (restricted)</li> <li>\u2705 Regular automated backups</li> <li>\u2705 Bastion with MFA</li> <li>\u2705 Monitoring and alerting</li> </ul>"},{"location":"configuration/examples/#template-variables","title":"Template Variables","text":"<p>You can use environment variables in your configs:</p> <pre><code>spec:\n  providers:\n    digitalocean:\n      token: ${DIGITALOCEAN_TOKEN}  # \ud83e\udda5 From environment\n      region: ${DO_REGION:-nyc3}    # \ud83e\udda5 Default to nyc3\n\n  network:\n    wireguard:\n      port: ${VPN_PORT:-51820}      # \ud83e\udda5 Default to 51820\n</code></pre> <p>Set before deploying:</p> <pre><code>export DIGITALOCEAN_TOKEN=\"dop_v1_...\"\nexport DO_REGION=\"sfo3\"\nexport VPN_PORT=\"51821\"\n\nsloth-kubernetes deploy --config cluster.yaml  # \ud83e\udda5\n</code></pre>"},{"location":"configuration/examples/#tips-for-writing-configs","title":"Tips for Writing Configs","text":"<p>Start Small \ud83e\udda5</p> <p>Begin with a simple config and add features gradually. Don't rush!</p> <p>Test in Dev First \ud83e\udda5</p> <p>Always test new configurations in development before production.</p> <p>Version Control \ud83e\udda5</p> <p>Keep your configs in Git for tracking and rollback capability.</p> <pre><code># Good structure\nk8s-clusters/\n\u251c\u2500\u2500 production.yaml\n\u251c\u2500\u2500 staging.yaml\n\u251c\u2500\u2500 development.yaml\n\u2514\u2500\u2500 examples/\n    \u251c\u2500\u2500 simple.yaml\n    \u251c\u2500\u2500 ha.yaml\n    \u2514\u2500\u2500 multi-cloud.yaml\n</code></pre> <p>Sloth Wisdom \ud83e\udda5</p> <p>\"A well-configured cluster is worth the wait. Take your time, get it right!\"</p> <p>Need more examples? Check out the examples directory in the repo! \ud83e\udda5</p>"},{"location":"getting-started/","title":"\ud83e\udda5 Getting Started","text":"<p>Welcome to Sloth Kubernetes! Let's get you up and running. Slowly, but surely!</p>"},{"location":"getting-started/#your-journey-begins","title":"Your Journey Begins \ud83e\udda5","text":"<p>Whether you're new to Kubernetes or a seasoned pro, Sloth Kubernetes makes multi-cloud cluster deployment simple. Just follow these steps at your own pace!</p> <p>The Sloth Philosophy \ud83e\udda5</p> <p>Why rush? Good clusters are deployed slowly and carefully. We'll get there together!</p>"},{"location":"getting-started/#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p>\ud83d\udce6 Installation</p> <p>Download and install Sloth Kubernetes</p> <p>Time: 2 minutes \u23f1\ufe0f</p> <p> Install Now</p> </li> <li> <p>\ud83d\ude80 Quick Start</p> <p>Deploy your first cluster</p> <p>Time: 5 minutes \u23f1\ufe0f</p> <p> Quick Start</p> </li> <li> <p>\ud83c\udfaf First Cluster</p> <p>Detailed walkthrough with explanations</p> <p>Time: 15 minutes \u23f1\ufe0f</p> <p> First Cluster</p> </li> <li> <p>\ud83d\udd2e What's Next?</p> <p>Explore advanced features</p> <p>Time: Whenever you're ready! \ud83e\udda5</p> <p> Next Steps</p> </li> </ul>"},{"location":"getting-started/#learning-path","title":"Learning Path","text":"<p>Follow this path to become a Sloth Kubernetes expert! \ud83e\udda5</p> <pre><code>graph LR\n    A[\ud83d\udce6 Installation] --&gt; B[\ud83d\ude80 Quick Start]\n    B --&gt; C[\ud83c\udfaf First Cluster]\n    C --&gt; D[\u2699\ufe0f Configuration]\n    D --&gt; E[\ud83c\udf93 Advanced Topics]\n    E --&gt; F[\ud83e\udda5 Sloth Master!]\n\n    style A fill:#8B4513,stroke:#D2691E,color:#fff\n    style B fill:#8B4513,stroke:#D2691E,color:#fff\n    style C fill:#8B4513,stroke:#D2691E,color:#fff\n    style D fill:#8B4513,stroke:#D2691E,color:#fff\n    style E fill:#8B4513,stroke:#D2691E,color:#fff\n    style F fill:#228B22,stroke:#32CD32,color:#fff</code></pre>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you start, make sure you have:</p>"},{"location":"getting-started/#required","title":"Required \u2705","text":"<ul> <li>Cloud Provider Account - DigitalOcean and/or Linode</li> <li>API Tokens - Read/Write access from your provider</li> <li>Basic Linux Knowledge - Understanding of SSH and command line</li> </ul>"},{"location":"getting-started/#optional-but-helpful","title":"Optional (but helpful) \ud83e\udda5","text":"<ul> <li>kubectl - For managing your cluster after deployment</li> <li>SSH Keys - For accessing nodes directly</li> <li>Git - For GitOps workflows</li> </ul> <p>Zero Installation Dependencies! \ud83e\udda5</p> <p>Unlike other tools, Sloth Kubernetes doesn't require Pulumi CLI, Terraform, or any other external tools. Just one binary!</p>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this section, you'll be able to:</p> <ul> <li> Install Sloth Kubernetes on your system</li> <li> Configure cloud provider credentials</li> <li> Deploy a multi-cloud Kubernetes cluster</li> <li> Access and manage your cluster</li> <li> Scale nodes up and down</li> <li> Configure WireGuard VPN mesh</li> <li> Bootstrap GitOps with ArgoCD</li> </ul>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<p>Need assistance? We've got you! \ud83e\udda5</p> <ul> <li> <p>\ud83d\udcac Community Slack</p> <p>Chat with other sloths!</p> <p>Join Slack</p> </li> <li> <p>\ud83d\udcd6 Documentation</p> <p>Comprehensive guides</p> <p>Browse Docs</p> </li> <li> <p>\ud83d\udc1b GitHub Issues</p> <p>Report bugs or request features</p> <p>Open Issue</p> </li> <li> <p>\ud83d\udce7 Email Support</p> <p>Get help from the team</p> <p>support@sloth-kubernetes.io</p> </li> </ul>"},{"location":"getting-started/#typical-timeline","title":"Typical Timeline","text":"<p>Here's how long each step typically takes:</p> Step Time Details Installation 2 min Download binary, configure tokens Quick Start 5 min Deploy simple cluster First Cluster 15 min Detailed walkthrough Advanced Config 30 min Custom configurations Production Deploy 45 min Full HA production cluster <p>Sloth Speed \ud83e\udda5</p> <p>These times are estimates. Take your time! The sloth way is to do things slowly and correctly.</p>"},{"location":"getting-started/#architecture-overview","title":"Architecture Overview","text":"<p>Before diving in, here's what Sloth Kubernetes will build for you:</p> <pre><code>\ud83e\udda5 Multi-Cloud Kubernetes Cluster \ud83e\udda5\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Your Kubernetes Cluster                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  DigitalOcean      \u2502      \u2502     Linode         \u2502     \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502      \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502     \u2502\n\u2502  \u2502  \u2502 Master Node  \u2502  \u2502      \u2502  \u2502 Master Node  \u2502  \u2502     \u2502\n\u2502  \u2502  \u2502   (etcd)  \ud83e\udda5 \u2502  \u2502      \u2502  \u2502   (etcd)  \ud83e\udda5 \u2502  \u2502     \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502      \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502     \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502      \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502     \u2502\n\u2502  \u2502  \u2502 Worker Node  \u2502  \u2502      \u2502  \u2502 Worker Node  \u2502  \u2502     \u2502\n\u2502  \u2502  \u2502   (apps)  \ud83e\udda5 \u2502  \u2502      \u2502  \u2502   (apps)  \ud83e\udda5 \u2502  \u2502     \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502      \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502            \u2502                           \u2502                 \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u25ba WireGuard VPN \u25c4\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                    (10.8.0.0/24) \ud83d\udd10                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Features:</p> <ul> <li>\ud83c\udf0d Multi-Cloud - Nodes across multiple providers</li> <li>\ud83d\udd10 Encrypted - WireGuard VPN mesh</li> <li>\ud83c\udfaf High Availability - Multiple masters with etcd</li> <li>\ud83c\udf33 GitOps Ready - ArgoCD bootstrap support</li> <li>\ud83e\udda5 Simple - One binary, one config file</li> </ul>"},{"location":"getting-started/#ready-to-start","title":"Ready to Start? \ud83e\udda5","text":"<p>Let's begin your sloth journey! Choose your path:</p> <p>Recommended Path</p> <p>Start with Installation \u2192 Quick Start \u2192 First Cluster</p>   [Install Now](installation.md){ .md-button .md-button--primary .md-button--lg } [Quick Start](quickstart.md){ .md-button .md-button--lg }   <p>Sloth Proverb \ud83e\udda5</p> <p>\"Every expert was once a beginner. Take your time, learn slowly, succeed surely!\"</p>"},{"location":"getting-started/installation/","title":"\ud83e\udda5 Installation","text":"<p>Get Sloth Kubernetes up and running. Slowly, but surely!</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>The Sloth Way \ud83e\udda5</p> <p>We keep dependencies minimal. You only need API tokens from your cloud providers!</p> <p>Before you start, make sure you have:</p> <ul> <li>\u2705 Cloud Provider Account - DigitalOcean and/or Linode</li> <li>\u2705 API Tokens - From your cloud provider(s)</li> <li>\u2705 SSH Access - For node management (optional but recommended)</li> </ul> <p>That's it! No kubectl, no Pulumi CLI, no Terraform. Just one lazy sloth binary! \ud83e\udda5</p>"},{"location":"getting-started/installation/#download-binary","title":"Download Binary","text":""},{"location":"getting-started/installation/#option-1-latest-release-recommended","title":"Option 1: Latest Release (Recommended)","text":"<p>Download the pre-compiled binary for your platform:</p> Linux (x64)macOS (Intel)macOS (Apple Silicon) <pre><code># Download latest release\ncurl -L https://github.com/yourusername/sloth-kubernetes/releases/latest/download/sloth-kubernetes-linux-amd64 -o sloth-kubernetes\n\n# Make executable\nchmod +x sloth-kubernetes\n\n# Move to PATH\nsudo mv sloth-kubernetes /usr/local/bin/\n\n# Verify installation \ud83e\udda5\nsloth-kubernetes version\n</code></pre> <pre><code># Download latest release\ncurl -L https://github.com/yourusername/sloth-kubernetes/releases/latest/download/sloth-kubernetes-darwin-amd64 -o sloth-kubernetes\n\n# Make executable\nchmod +x sloth-kubernetes\n\n# Move to PATH\nsudo mv sloth-kubernetes /usr/local/bin/\n\n# Verify installation \ud83e\udda5\nsloth-kubernetes version\n</code></pre> <pre><code># Download latest release\ncurl -L https://github.com/yourusername/sloth-kubernetes/releases/latest/download/sloth-kubernetes-darwin-arm64 -o sloth-kubernetes\n\n# Make executable\nchmod +x sloth-kubernetes\n\n# Move to PATH\nsudo mv sloth-kubernetes /usr/local/bin/\n\n# Verify installation \ud83e\udda5\nsloth-kubernetes version\n</code></pre>"},{"location":"getting-started/installation/#option-2-build-from-source","title":"Option 2: Build from Source","text":"<p>For the adventurous sloths who want the latest features! \ud83e\udda5</p> <pre><code># Clone the repository\ngit clone https://github.com/yourusername/sloth-kubernetes.git\ncd sloth-kubernetes\n\n# Build (requires Go 1.23+)\ngo build -o sloth-kubernetes\n\n# Move to PATH\nsudo mv sloth-kubernetes /usr/local/bin/\n\n# Verify \ud83e\udda5\nsloth-kubernetes version\n</code></pre>"},{"location":"getting-started/installation/#configure-api-tokens","title":"Configure API Tokens","text":"<p>Sloth Kubernetes needs API tokens to create resources in your cloud providers.</p>"},{"location":"getting-started/installation/#digitalocean","title":"DigitalOcean","text":"<ol> <li>Go to DigitalOcean API Tokens</li> <li>Click \"Generate New Token\"</li> <li>Name it \"sloth-kubernetes\" \ud83e\udda5</li> <li>Select Read &amp; Write scope</li> <li>Copy the token</li> </ol> <pre><code># Set environment variable\nexport DIGITALOCEAN_TOKEN=\"dop_v1_abc123...\"\n\n# Or add to your shell profile (~/.bashrc, ~/.zshrc)\necho 'export DIGITALOCEAN_TOKEN=\"dop_v1_abc123...\"' &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"getting-started/installation/#linode","title":"Linode","text":"<ol> <li>Go to Linode API Tokens</li> <li>Click \"Create a Personal Access Token\"</li> <li>Label it \"sloth-kubernetes\" \ud83e\udda5</li> <li>Select Read/Write for Linodes, VPCs</li> <li>Copy the token</li> </ol> <pre><code># Set environment variable\nexport LINODE_TOKEN=\"abc123...\"\n\n# Or add to your shell profile\necho 'export LINODE_TOKEN=\"abc123...\"' &gt;&gt; ~/.bashrc\n</code></pre> <p>Keep Your Tokens Safe \ud83e\udda5</p> <p>Never commit API tokens to Git! Use environment variables or secret management tools.</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Let's make sure everything is working:</p> <pre><code># Check version\nsloth-kubernetes version\n\n# View help\nsloth-kubernetes --help\n\n# Test configuration (dry run)\nsloth-kubernetes deploy --config examples/simple-cluster.yaml --dry-run\n</code></pre> <p>You should see output like:</p> <pre><code>\ud83e\udda5 Sloth Kubernetes v1.0.0\nSlowly, but surely deploying your cluster...\n</code></pre>"},{"location":"getting-started/installation/#optional-shell-completion","title":"Optional: Shell Completion","text":"<p>Make your life easier with shell completion! \ud83e\udda5</p> BashZshFish <pre><code># Generate completion script\nsloth-kubernetes completion bash &gt; /tmp/sloth-completion.bash\n\n# Install system-wide\nsudo mv /tmp/sloth-completion.bash /etc/bash_completion.d/sloth-kubernetes\n\n# Or just for your user\necho 'source &lt;(sloth-kubernetes completion bash)' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <pre><code># Generate completion script\nsloth-kubernetes completion zsh &gt; \"${fpath[1]}/_sloth-kubernetes\"\n\n# Or add to .zshrc\necho 'source &lt;(sloth-kubernetes completion zsh)' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre> <pre><code># Generate completion script\nsloth-kubernetes completion fish &gt; ~/.config/fish/completions/sloth-kubernetes.fish\n</code></pre>"},{"location":"getting-started/installation/#whats-next","title":"What's Next? \ud83e\udda5","text":"<p>Now that you're all set up, let's deploy your first cluster!</p> <ul> <li> <p>\ud83d\udcd8 Quick Start</p> <p>Deploy your first cluster in 5 minutes! \ud83e\udda5</p> <p> Quick Start</p> </li> <li> <p>\ud83c\udfaf First Cluster</p> <p>Step-by-step guide to your first production cluster \ud83e\udda5</p> <p> First Cluster</p> </li> <li> <p>\ud83d\udcda Configuration</p> <p>Learn about cluster configuration options \ud83e\udda5</p> <p> Configuration</p> </li> </ul> <p>Sloth Wisdom \ud83e\udda5</p> <p>\"The journey of a thousand miles begins with a single step... but take your time!\"</p>"},{"location":"getting-started/quickstart/","title":"\ud83e\udda5 Quick Start","text":"<p>Deploy a production-ready Kubernetes cluster in 5 minutes. Slowly, but surely!</p>"},{"location":"getting-started/quickstart/#overview","title":"Overview","text":"<p>This quick start will guide you through deploying your first multi-cloud Kubernetes cluster with:</p> <ul> <li>\u2705 3 master nodes for high availability</li> <li>\u2705 2 worker nodes across multiple clouds</li> <li>\u2705 WireGuard VPN mesh (automatic)</li> <li>\u2705 RKE2 Kubernetes distribution</li> <li>\u2705 Encrypted secrets at rest</li> </ul> <p>Time: 5-8 minutes \u2615\ud83e\udda5</p>"},{"location":"getting-started/quickstart/#step-1-prerequisites","title":"Step 1: Prerequisites","text":"<p>Make sure you have:</p> <ol> <li>Sloth Kubernetes binary installed (Installation Guide)</li> <li>API tokens configured as environment variables:</li> </ol> <pre><code>export DIGITALOCEAN_TOKEN=\"dop_v1_your_token_here\"\nexport LINODE_TOKEN=\"your_linode_token_here\"\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-create-configuration-file","title":"Step 2: Create Configuration File","text":"<p>Create a file named <code>my-first-cluster.yaml</code>:</p> <pre><code>apiVersion: kubernetes-create.io/v1\nkind: Cluster\nmetadata:\n  name: my-first-cluster  # \ud83e\udda5 Name your sloth cluster\n  labels:\n    environment: demo\n    managed-by: sloth\n\nspec:\n  # Cloud providers configuration\n  providers:\n    digitalocean:\n      enabled: true\n      token: ${DIGITALOCEAN_TOKEN}  # \ud83e\udda5 From environment\n      region: nyc3\n      vpc:\n        create: true\n        cidr: 10.10.0.0/16\n\n    linode:\n      enabled: true\n      token: ${LINODE_TOKEN}  # \ud83e\udda5 From environment\n      region: us-east\n      vpc:\n        create: true\n        cidr: 10.11.0.0/16\n\n  # Network configuration\n  network:\n    wireguard:\n      create: true  # \ud83e\udda5 Auto-create VPN mesh\n      meshNetworking: true\n      subnet: 10.8.0.0/24\n\n  # Kubernetes configuration\n  kubernetes:\n    distribution: rke2\n    version: v1.28.5+rke2r1\n    rke2:\n      secretsEncryption: true  # \ud83e\udda5 Secure by default\n\n  # Node pools\n  nodePools:\n    # DigitalOcean masters\n    - name: do-masters\n      provider: digitalocean\n      count: 1\n      roles: [master]\n      size: s-2vcpu-4gb\n\n    # Linode masters (for HA)\n    - name: linode-masters\n      provider: linode\n      count: 2  # \ud83e\udda5 3 total masters for quorum\n      roles: [master]\n      size: g6-standard-2\n\n    # Workers across both clouds\n    - name: do-workers\n      provider: digitalocean\n      count: 1\n      roles: [worker]\n      size: s-2vcpu-4gb\n\n    - name: linode-workers\n      provider: linode\n      count: 1\n      roles: [worker]\n      size: g6-standard-2\n</code></pre> <p>Sloth Tip \ud83e\udda5</p> <p>This configuration creates a true multi-cloud HA cluster with masters and workers across both DigitalOcean and Linode!</p>"},{"location":"getting-started/quickstart/#step-3-deploy","title":"Step 3: Deploy! \ud83e\udda5","text":"<p>Now let's deploy your cluster:</p> <pre><code># Deploy the cluster\nsloth-kubernetes deploy --config my-first-cluster.yaml\n\n# The sloth will:\n# \ud83e\udda5 Create VPCs on both clouds\n# \ud83e\udda5 Deploy WireGuard VPN server\n# \ud83e\udda5 Provision 5 nodes (3 masters, 2 workers)\n# \ud83e\udda5 Install RKE2 on all nodes\n# \ud83e\udda5 Configure encrypted mesh networking\n# \ud83e\udda5 Generate kubeconfig\n</code></pre> <p>You'll see output like:</p> <pre><code>\ud83e\udda5 Sloth Kubernetes Deployment\nSlowly, but surely deploying your cluster...\n\n\u2713 Creating DigitalOcean VPC (10.10.0.0/16)\n\u2713 Creating Linode VPC (10.11.0.0/16)\n\u2713 Deploying WireGuard VPN server\n\u2713 Provisioning master nodes (1/3)\n\u2713 Provisioning master nodes (2/3)\n\u2713 Provisioning master nodes (3/3)\n\u2713 Installing RKE2 on masters\n\u2713 Provisioning worker nodes (1/2)\n\u2713 Provisioning worker nodes (2/2)\n\u2713 Installing RKE2 on workers\n\u2713 Configuring WireGuard mesh\n\u2713 Generating kubeconfig\n\n\ud83e\udda5 Cluster deployed successfully!\n   Time elapsed: 7m 32s\n\n   Kubeconfig: ./my-first-cluster-kubeconfig.yaml\n</code></pre> <p>Deployment Complete! \ud83e\udda5</p> <p>Your multi-cloud Kubernetes cluster is now running! Time to relax like a sloth! \ud83d\ude34</p>"},{"location":"getting-started/quickstart/#step-4-access-your-cluster","title":"Step 4: Access Your Cluster","text":"<p>Get the kubeconfig and start using your cluster:</p> <pre><code># Export kubeconfig\nexport KUBECONFIG=$(pwd)/my-first-cluster-kubeconfig.yaml\n\n# Or copy to default location\nmkdir -p ~/.kube\ncp my-first-cluster-kubeconfig.yaml ~/.kube/config\n\n# Verify cluster access\nkubectl get nodes\n\n# You should see:\nNAME                    STATUS   ROLES                       AGE   VERSION\ndo-master-1             Ready    control-plane,etcd,master   7m    v1.28.5+rke2r1\nlinode-master-1         Ready    control-plane,etcd,master   7m    v1.28.5+rke2r1\nlinode-master-2         Ready    control-plane,etcd,master   6m    v1.28.5+rke2r1\ndo-worker-1             Ready    worker                      5m    v1.28.5+rke2r1\nlinode-worker-1         Ready    worker                      5m    v1.28.5+rke2r1\n</code></pre> <pre><code># Check cluster info\nkubectl cluster-info\n\n# View pods across all namespaces\nkubectl get pods -A\n\n# Deploy a test application \ud83e\udda5\nkubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --port=80 --type=LoadBalancer\nkubectl get svc\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-what-just-happened","title":"Step 5: What Just Happened? \ud83e\udda5","text":"<p>Let's understand what the sloth built for you:</p>"},{"location":"getting-started/quickstart/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>        \ud83e\udda5 Your Multi-Cloud Cluster \ud83e\udda5\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   DigitalOcean NYC3     \u2502  \u2502     Linode US-East      \u2502\n\u2502                         \u2502  \u2502                         \u2502\n\u2502  \u2022 Master 1        \ud83e\udda5   \u2502  \u2502  \u2022 Master 2        \ud83e\udda5   \u2502\n\u2502  \u2022 Worker 1        \ud83e\udda5   \u2502  \u2502  \u2022 Master 3        \ud83e\udda5   \u2502\n\u2502                         \u2502  \u2502  \u2022 Worker 1        \ud83e\udda5   \u2502\n\u2502  VPC: 10.10.0.0/16      \u2502  \u2502  VPC: 10.11.0.0/16      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                          \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u25ba WireGuard \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   10.8.0.0/24\n                      \ud83d\udd10\n</code></pre>"},{"location":"getting-started/quickstart/#what-was-created","title":"What Was Created","text":"Component Details VPCs 2 VPCs (1 per cloud) with private networking VPN WireGuard mesh connecting all nodes Masters 3 control plane nodes across 2 clouds Workers 2 worker nodes for your workloads Kubernetes RKE2 v1.28.5 with encrypted secrets Networking Private mesh + public access"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps \ud83e\udda5","text":"<p>Now that your cluster is running, explore more features:</p> <ul> <li> <p>\ud83d\udcd6 Add More Nodes</p> <p>Scale your cluster up! \ud83e\udda5</p> <p> Manage Nodes</p> </li> <li> <p>\ud83d\udd10 Configure VPN</p> <p>Access your cluster securely \ud83e\udda5</p> <p> VPN Management</p> </li> <li> <p>\ud83c\udf33 Enable GitOps</p> <p>Bootstrap ArgoCD for GitOps \ud83e\udda5</p> <p> GitOps Guide</p> </li> <li> <p>\u2699\ufe0f Advanced Config</p> <p>Customize everything \ud83e\udda5</p> <p> Configuration</p> </li> </ul>"},{"location":"getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quickstart/#common-issues","title":"Common Issues","text":"Deployment stuck at 'Provisioning nodes' <p>This is normal! Cloud providers can take 2-3 minutes to provision instances. The sloth is patient! \ud83e\udda5</p> VPN connection failed <p>Check that: - Firewalls allow UDP port 51820 - VPC CIDR ranges don't overlap - Nodes have public IPs for initial setup</p> kubectl connection refused <p>Verify: <pre><code># Check kubeconfig path\necho $KUBECONFIG\n\n# Test with explicit path\nkubectl --kubeconfig=my-first-cluster-kubeconfig.yaml get nodes\n</code></pre></p> <p>For more help, see Troubleshooting Guide \ud83e\udda5</p>"},{"location":"getting-started/quickstart/#clean-up-optional","title":"Clean Up (Optional)","text":"<p>When you're done testing, clean up resources:</p> <pre><code># Destroy the cluster\nsloth-kubernetes destroy --config my-first-cluster.yaml\n\n# The sloth will:\n# \ud83e\udda5 Remove all nodes\n# \ud83e\udda5 Delete VPCs\n# \ud83e\udda5 Clean up VPN server\n# \ud83e\udda5 Remove local state\n</code></pre> <p>Destruction is Permanent \ud83e\udda5</p> <p>This will permanently delete all cluster resources. Make sure you've backed up any data!</p> <p>Ancient Sloth Wisdom \ud83e\udda5</p> <p>\"A cluster deployed slowly is a cluster deployed correctly!\"</p> <p>Congratulations! You've deployed your first Sloth Kubernetes cluster! \ud83e\udda5\ud83c\udf89</p>"},{"location":"user-guide/cli-reference/","title":"\ud83e\udda5 CLI Reference","text":"<p>Complete reference for all Sloth Kubernetes commands. Slowly, but thoroughly documented!</p>"},{"location":"user-guide/cli-reference/#global-flags","title":"Global Flags","text":"<p>These flags work with all commands:</p> Flag Description Default <code>--help, -h</code> Show help for command - <code>--version, -v</code> Show version - <code>--debug</code> Enable debug logging <code>false</code> <code>--config, -c</code> Path to config file <code>cluster.yaml</code>"},{"location":"user-guide/cli-reference/#commands-overview","title":"Commands Overview","text":"<pre><code>sloth-kubernetes [command] [flags]\n</code></pre> <p>Available Commands:</p> <ul> <li><code>deploy</code> - Deploy a Kubernetes cluster \ud83e\udda5</li> <li><code>destroy</code> - Destroy a cluster \ud83e\udda5</li> <li><code>nodes</code> - Manage cluster nodes \ud83e\udda5</li> <li><code>vpn</code> - Manage WireGuard VPN \ud83e\udda5</li> <li><code>stacks</code> - Manage Pulumi stacks \ud83e\udda5</li> <li><code>kubeconfig</code> - Generate kubeconfig \ud83e\udda5</li> <li><code>version</code> - Show version info \ud83e\udda5</li> </ul>"},{"location":"user-guide/cli-reference/#deploy","title":"<code>deploy</code>","text":"<p>Deploy a new Kubernetes cluster or update an existing one.</p>"},{"location":"user-guide/cli-reference/#usage","title":"Usage","text":"<pre><code>sloth-kubernetes deploy [flags]\n</code></pre>"},{"location":"user-guide/cli-reference/#flags","title":"Flags","text":"Flag Type Description Required Default <code>--config, -c</code> string Path to cluster config file Yes <code>cluster.yaml</code> <code>--dry-run</code> bool Preview changes without applying No <code>false</code> <code>--auto-approve</code> bool Skip confirmation prompt No <code>false</code> <code>--parallel</code> int Max parallel operations No <code>10</code> <code>--timeout</code> duration Deployment timeout No <code>30m</code>"},{"location":"user-guide/cli-reference/#examples","title":"Examples","text":"<pre><code># Deploy with default config \ud83e\udda5\nsloth-kubernetes deploy\n\n# Deploy with custom config\nsloth-kubernetes deploy --config production.yaml\n\n# Dry run (preview changes)\nsloth-kubernetes deploy --dry-run\n\n# Auto-approve without confirmation\nsloth-kubernetes deploy --auto-approve\n\n# Deploy with timeout\nsloth-kubernetes deploy --timeout 45m\n</code></pre>"},{"location":"user-guide/cli-reference/#output","title":"Output","text":"<pre><code>\ud83e\udda5 Sloth Kubernetes Deployment\nSlowly, but surely deploying your cluster...\n\nStack: my-cluster\nConfig: cluster.yaml\n\nPreview:\n  + 2 VPCs\n  + 1 WireGuard VPN server\n  + 3 Master nodes\n  + 2 Worker nodes\n  + 5 DNS records\n\nContinue with deployment? [y/N]: y\n\n\u2713 Creating resources... (5m 32s)\n\u2713 Installing Kubernetes... (3m 45s)\n\u2713 Configuring VPN mesh... (1m 12s)\n\n\ud83e\udda5 Deployment complete!\n   Time: 10m 29s\n   Kubeconfig: ./my-cluster-kubeconfig.yaml\n</code></pre>"},{"location":"user-guide/cli-reference/#destroy","title":"<code>destroy</code>","text":"<p>Destroy a Kubernetes cluster and all associated resources.</p>"},{"location":"user-guide/cli-reference/#usage_1","title":"Usage","text":"<pre><code>sloth-kubernetes destroy [flags]\n</code></pre>"},{"location":"user-guide/cli-reference/#flags_1","title":"Flags","text":"Flag Type Description Required Default <code>--config, -c</code> string Path to cluster config file Yes <code>cluster.yaml</code> <code>--force, -f</code> bool Skip confirmation prompt No <code>false</code> <code>--remove-state</code> bool Also remove state files No <code>false</code>"},{"location":"user-guide/cli-reference/#examples_1","title":"Examples","text":"<pre><code># Destroy cluster \ud83e\udda5\nsloth-kubernetes destroy\n\n# Force destroy (no confirmation)\nsloth-kubernetes destroy --force\n\n# Destroy and remove state\nsloth-kubernetes destroy --remove-state\n</code></pre>"},{"location":"user-guide/cli-reference/#output_1","title":"Output","text":"<pre><code>\ud83e\udda5 Sloth Kubernetes Destruction\nSlowly tearing down your cluster...\n\n\u26a0 WARNING: This will destroy:\n  - 2 VPCs\n  - 1 VPN server\n  - 5 nodes (3 masters, 2 workers)\n  - All data and volumes\n\nType cluster name to confirm: my-cluster\n\n\u2713 Removing nodes... (3m 12s)\n\u2713 Destroying VPN... (45s)\n\u2713 Deleting VPCs... (1m 5s)\n\n\ud83e\udda5 Cluster destroyed successfully!\n</code></pre>"},{"location":"user-guide/cli-reference/#nodes","title":"<code>nodes</code>","text":"<p>Manage cluster nodes: list, add, remove, or drain.</p>"},{"location":"user-guide/cli-reference/#subcommands","title":"Subcommands","text":"<ul> <li><code>nodes list</code> - List all nodes \ud83e\udda5</li> <li><code>nodes add</code> - Add nodes to cluster \ud83e\udda5</li> <li><code>nodes remove</code> - Remove nodes from cluster \ud83e\udda5</li> <li><code>nodes drain</code> - Drain a node for maintenance \ud83e\udda5</li> </ul>"},{"location":"user-guide/cli-reference/#nodes-list","title":"<code>nodes list</code>","text":"<p>List all nodes in the cluster.</p> <pre><code>sloth-kubernetes nodes list [flags]\n</code></pre> <p>Flags:</p> Flag Type Description Default <code>--config, -c</code> string Cluster config <code>cluster.yaml</code> <code>--output, -o</code> string Output format: <code>table</code>, <code>json</code>, <code>yaml</code> <code>table</code> <p>Example:</p> <pre><code># List nodes \ud83e\udda5\nsloth-kubernetes nodes list\n\n# Output as JSON\nsloth-kubernetes nodes list -o json\n</code></pre> <p>Output:</p> <pre><code>\ud83e\udda5 Cluster Nodes\n\nNAME              PROVIDER        ROLE     STATUS   IP            REGION\ndo-master-1       digitalocean    master   Ready    10.10.1.5     nyc3\nlinode-master-1   linode          master   Ready    10.11.1.5     us-east\nlinode-master-2   linode          master   Ready    10.11.1.6     us-east\ndo-worker-1       digitalocean    worker   Ready    10.10.1.10    nyc3\nlinode-worker-1   linode          worker   Ready    10.11.1.10    us-east\n\nTotal: 5 nodes (3 masters, 2 workers)\n</code></pre>"},{"location":"user-guide/cli-reference/#nodes-add","title":"<code>nodes add</code>","text":"<p>Add new nodes to an existing cluster.</p> <pre><code>sloth-kubernetes nodes add --pool POOL_NAME --count COUNT [flags]\n</code></pre> <p>Flags:</p> Flag Type Description Required <code>--pool</code> string Node pool name from config Yes <code>--count</code> int Number of nodes to add Yes <code>--config, -c</code> string Cluster config No <p>Example:</p> <pre><code># Add 2 workers to linode-workers pool \ud83e\udda5\nsloth-kubernetes nodes add --pool linode-workers --count 2\n\n# Add 1 master\nsloth-kubernetes nodes add --pool do-masters --count 1\n</code></pre>"},{"location":"user-guide/cli-reference/#nodes-remove","title":"<code>nodes remove</code>","text":"<p>Remove nodes from the cluster.</p> <pre><code>sloth-kubernetes nodes remove NODE_NAME [flags]\n</code></pre> <p>Flags:</p> Flag Type Description Default <code>--force, -f</code> bool Skip drain and delete immediately <code>false</code> <code>--drain-timeout</code> duration Timeout for draining <code>5m</code> <p>Example:</p> <pre><code># Remove a node (with graceful drain) \ud83e\udda5\nsloth-kubernetes nodes remove do-worker-2\n\n# Force remove without drain\nsloth-kubernetes nodes remove do-worker-2 --force\n</code></pre>"},{"location":"user-guide/cli-reference/#nodes-drain","title":"<code>nodes drain</code>","text":"<p>Drain a node for maintenance.</p> <pre><code>sloth-kubernetes nodes drain NODE_NAME [flags]\n</code></pre> <p>Example:</p> <pre><code># Drain node for maintenance \ud83e\udda5\nsloth-kubernetes nodes drain do-worker-1\n</code></pre>"},{"location":"user-guide/cli-reference/#vpn","title":"<code>vpn</code>","text":"<p>Manage WireGuard VPN configuration and client access.</p>"},{"location":"user-guide/cli-reference/#subcommands_1","title":"Subcommands","text":"<ul> <li><code>vpn status</code> - Show VPN status \ud83e\udda5</li> <li><code>vpn client-config</code> - Generate client config \ud83e\udda5</li> <li><code>vpn add-client</code> - Add new VPN client \ud83e\udda5</li> <li><code>vpn remove-client</code> - Remove VPN client \ud83e\udda5</li> </ul>"},{"location":"user-guide/cli-reference/#vpn-status","title":"<code>vpn status</code>","text":"<p>Show WireGuard VPN status and connected clients.</p> <pre><code>sloth-kubernetes vpn status [flags]\n</code></pre> <p>Example:</p> <pre><code># Check VPN status \ud83e\udda5\nsloth-kubernetes vpn status\n</code></pre> <p>Output:</p> <pre><code>\ud83e\udda5 WireGuard VPN Status\n\nServer: 203.0.113.10 (nyc3)\nSubnet: 10.8.0.0/24\nPort: 51820\n\nConnected Nodes:\n  do-master-1      10.8.0.2   \u2713 Connected\n  linode-master-1  10.8.0.3   \u2713 Connected\n  linode-master-2  10.8.0.4   \u2713 Connected\n  do-worker-1      10.8.0.10  \u2713 Connected\n  linode-worker-1  10.8.0.11  \u2713 Connected\n\nClients:\n  my-laptop        10.8.0.100 \u2713 Connected\n</code></pre>"},{"location":"user-guide/cli-reference/#vpn-client-config","title":"<code>vpn client-config</code>","text":"<p>Generate WireGuard client configuration.</p> <pre><code>sloth-kubernetes vpn client-config --name CLIENT_NAME [flags]\n</code></pre> <p>Flags:</p> Flag Type Description Required <code>--name</code> string Client name Yes <code>--output, -o</code> string Output file path No <p>Example:</p> <pre><code># Generate client config \ud83e\udda5\nsloth-kubernetes vpn client-config --name my-laptop\n\n# Save to file\nsloth-kubernetes vpn client-config --name my-laptop -o laptop.conf\n</code></pre> <p>Output:</p> <pre><code>\ud83e\udda5 WireGuard Client Configuration\n\n[Interface]\nPrivateKey = &lt;generated-private-key&gt;\nAddress = 10.8.0.100/24\nDNS = 10.8.0.1\n\n[Peer]\nPublicKey = &lt;server-public-key&gt;\nEndpoint = 203.0.113.10:51820\nAllowedIPs = 10.8.0.0/24, 10.10.0.0/16, 10.11.0.0/16\nPersistentKeepalive = 25\n\nSaved to: my-laptop.conf\n</code></pre>"},{"location":"user-guide/cli-reference/#stacks","title":"<code>stacks</code>","text":"<p>Manage Pulumi stacks for cluster state.</p>"},{"location":"user-guide/cli-reference/#subcommands_2","title":"Subcommands","text":"<ul> <li><code>stacks list</code> - List all stacks \ud83e\udda5</li> <li><code>stacks state list</code> - List stack resources \ud83e\udda5</li> <li><code>stacks state delete</code> - Delete specific resources \ud83e\udda5</li> </ul>"},{"location":"user-guide/cli-reference/#stacks-list","title":"<code>stacks list</code>","text":"<p>List all Pulumi stacks.</p> <pre><code>sloth-kubernetes stacks list\n</code></pre> <p>Example:</p> <pre><code># List stacks \ud83e\udda5\nsloth-kubernetes stacks list\n</code></pre> <p>Output:</p> <pre><code>\ud83e\udda5 Pulumi Stacks\n\nNAME              LAST UPDATE       RESOURCE COUNT\nmy-cluster        2 hours ago       47 resources\nstaging-cluster   1 day ago         23 resources\n</code></pre>"},{"location":"user-guide/cli-reference/#stacks-state-list","title":"<code>stacks state list</code>","text":"<p>List all resources in a stack.</p> <pre><code>sloth-kubernetes stacks state list [flags]\n</code></pre> <p>Flags:</p> Flag Type Description Default <code>--config, -c</code> string Cluster config <code>cluster.yaml</code> <code>--type</code> string Filter by resource type - <p>Example:</p> <pre><code># List all resources \ud83e\udda5\nsloth-kubernetes stacks state list\n\n# Filter by type\nsloth-kubernetes stacks state list --type digitalocean:Droplet\n</code></pre>"},{"location":"user-guide/cli-reference/#kubeconfig","title":"<code>kubeconfig</code>","text":"<p>Generate kubeconfig for cluster access.</p>"},{"location":"user-guide/cli-reference/#usage_2","title":"Usage","text":"<pre><code>sloth-kubernetes kubeconfig [flags]\n</code></pre>"},{"location":"user-guide/cli-reference/#flags_2","title":"Flags","text":"Flag Type Description Default <code>--config, -c</code> string Cluster config <code>cluster.yaml</code> <code>--output, -o</code> string Output file stdout"},{"location":"user-guide/cli-reference/#examples_2","title":"Examples","text":"<pre><code># Print kubeconfig \ud83e\udda5\nsloth-kubernetes kubeconfig\n\n# Save to file\nsloth-kubernetes kubeconfig -o ~/.kube/config\n\n# Use immediately with kubectl\nexport KUBECONFIG=$(sloth-kubernetes kubeconfig -o /tmp/kubeconfig.yaml)\nkubectl get nodes\n</code></pre>"},{"location":"user-guide/cli-reference/#version","title":"<code>version</code>","text":"<p>Show version information.</p>"},{"location":"user-guide/cli-reference/#usage_3","title":"Usage","text":"<pre><code>sloth-kubernetes version\n</code></pre>"},{"location":"user-guide/cli-reference/#output_2","title":"Output","text":"<pre><code>\ud83e\udda5 Sloth Kubernetes\nVersion: 1.0.0\nGit Commit: abc123\nBuilt: 2025-01-15T10:30:00Z\nGo Version: go1.23.4\nPlatform: darwin/arm64\n</code></pre>"},{"location":"user-guide/cli-reference/#environment-variables","title":"Environment Variables","text":"<p>Sloth Kubernetes supports these environment variables:</p> Variable Description Example <code>DIGITALOCEAN_TOKEN</code> DigitalOcean API token <code>dop_v1_abc123...</code> <code>LINODE_TOKEN</code> Linode API token <code>abc123...</code> <code>SLOTH_DEBUG</code> Enable debug mode <code>true</code> <code>SLOTH_STATE_DIR</code> State directory <code>~/.sloth</code>"},{"location":"user-guide/cli-reference/#exit-codes","title":"Exit Codes","text":"Code Meaning <code>0</code> Success \ud83e\udda5 <code>1</code> General error <code>2</code> Configuration error <code>3</code> Network error <code>4</code> API error <code>5</code> Timeout <p>Sloth Wisdom \ud83e\udda5</p> <p>\"With great CLIs comes great responsibility... but take your time using them!\"</p>"}]}